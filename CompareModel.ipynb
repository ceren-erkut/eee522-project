{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchview import draw_graph\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "# get the current directory\n",
    "cdir = os.getcwd()\n",
    "# get the parent directory\n",
    "pdir = os.path.abspath(os.path.join(cdir, os.pardir))\n",
    "# get the parent directory of the parent directory\n",
    "pdir = os.path.abspath(os.path.join(pdir, os.pardir))\n",
    "sys.path.append(pdir+'/functions/')\n",
    "# from functions import dir_manager as dm\n",
    "import dir_manager as dm\n",
    "import functions_model as fm\n",
    "\n",
    "# import functions module\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_epochs = 50\n",
    "# batch_size_train = 64\n",
    "# batch_size_test = 1000\n",
    "# learning_rate = 0.01\n",
    "# momentum = 0.5\n",
    "# log_interval = 10\n",
    "\n",
    "# random_seed = 1\n",
    "# torch.backends.cudnn.enabled = False\n",
    "# torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (13961, 4)\n",
      "test size (5984, 4)\n",
      "-----------\n",
      "train dataset dist {0: 1288, 1: 2831, 2: 4058, 3: 5784}\n",
      "test dataset dist {0: 552, 1: 1214, 2: 1739, 3: 2479}\n",
      "train dataset dimensions torch.Size([13961, 8, 25])\n",
      "Reshaping\n",
      "Reshaped train dataset dimensions torch.Size([13961, 8, 5, 5])\n",
      "Reshaped test dataset dimensions torch.Size([13961, 8, 5, 5])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "'''Load Directories'''\n",
    "# initialize the class\n",
    "dir_manager = dm.dir_manager()\n",
    "\n",
    "\n",
    "data_name = 'MUFC_4096_0_D0'\n",
    "data_name = 'MUFC_8192_512_D2'\n",
    "data_name = \"MUFC_spectogram_Zhai_PCA_25\"\n",
    "data_name = \"MUFC_spectogram_normalized_Zhai_PCA_25\"\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader, test_dataloader, input_data_length = fm.create_datasets(\n",
    "                    data_name,\n",
    "                    data_add=dir_manager.dir_dict['dataset'],\n",
    "                    test_size_ =0.30, \n",
    "                    random_s = 112,\n",
    "                    batch_size_=batch_size, \n",
    "                    shuffle_=True,\n",
    "                    reshape_size = [5,5]\n",
    "                    )\n",
    "print(input_data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2dd0f6eb670>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atzori(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Atzori, self).__init__()\n",
    "        # layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 8, out_channels = 32 , kernel_size = 3)\n",
    "        # In paper channel size and kernel size is unclear\n",
    "        \n",
    "        # layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32 , kernel_size = 3)        \n",
    "        self.pool = nn.AvgPool2d(3, 3)\n",
    "        \n",
    "        # layer 3      \n",
    "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64 , kernel_size = 5)        \n",
    "        self.pool2 = nn.AvgPool2d(3, 3)\n",
    "        \n",
    "        # layer 4\n",
    "        self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64 , kernel_size = (5,1) )\n",
    "        # it is spesific for kernel size (5,1)\n",
    "        \n",
    "        # layer 5\n",
    "        self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 64 , kernel_size = 1 )  \n",
    "        \n",
    "        \n",
    "\n",
    "        self.linear = nn.Linear( 320 , 4)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # layer 3\n",
    "        x = self.pool2(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # layer 4\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        # layer 5\n",
    "        x = F.relu(self.conv5(x))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.linear( x )\n",
    "\n",
    "        return F.softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Geng(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Geng, self).__init__()\n",
    "        # layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 8, out_channels = 64 , kernel_size = 3 , stride = 1)\n",
    "        # In paper, they feed 1x10 downsample emg (kernel=3, filter = 64)\n",
    "\n",
    "        # layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels = 64 , out_channels = 64 , kernel_size = 1 ,stride = 1)        \n",
    "\n",
    "        \n",
    "        # layer 3      \n",
    "        self.linear1 = nn.Linear( 246016 , 512 )\n",
    "        # layer 4\n",
    "        self.linear2 = nn.Linear( 512 , 512 )\n",
    "        # layer 5\n",
    "        self.linear3 = nn.Linear( 512 , 128 )\n",
    "\n",
    "      \n",
    "        \n",
    "\n",
    "        self.linear4 = nn.Linear( 128 , 4)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # layer 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        # layer 3\n",
    "\n",
    "        x = self.linear1( x )\n",
    "        \n",
    "        # layer 4\n",
    "        x = self.linear2( x )\n",
    "        \n",
    "        # layer 5\n",
    "        x = self.linear3( x )\n",
    "\n",
    "        x = self.linear4( x )\n",
    "        \n",
    "\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zhai(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Zhai, self).__init__()\n",
    "        # layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 8, out_channels = 4 , kernel_size = 4)\n",
    "        # in paper, defined input size 12 channel 5x5 image after spectogram\n",
    "        \n",
    "        # layer 2      \n",
    "        self.linear1 = nn.Linear( 16 , 32 )\n",
    "        self.dropout1 = nn.Dropout(p = 0.5)\n",
    "        # layer 3\n",
    "        self.linear2 = nn.Linear( 32 , 32 )\n",
    "        self.dropout2 = nn.Dropout(p = 0.5)\n",
    "        # layer output\n",
    "        self.linear3 = nn.Linear( 32 , 4 )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "    \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # layer 2\n",
    "        x = self.dropout1( self.linear1( x ) )\n",
    "        \n",
    "        # layer 3\n",
    "        x = self.dropout2( self.linear2( x ) )\n",
    "        \n",
    "        # layer 5\n",
    "        x = self.linear3( x )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best device available\n",
    "mps_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# mps_device = torch.device(\"cpu\")\n",
    "\n",
    "# create an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Epoch 1, LR 0.001\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.384187  [   32/13961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.203676  [ 3232/13961]\n",
      "loss: 1.251591  [ 6432/13961]\n",
      "loss: 1.169719  [ 9632/13961]\n",
      "loss: 1.130980  [12832/13961]\n",
      "time taken 1.1952595710754395\n",
      "Test Scores: \n",
      " Accuracy: 57.3%, F1:33.2%,  Test loss: 1.166423, Training loss:1.246743 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.48      0.77      0.60      1739\n",
      "         3.0       0.65      0.84      0.73      2479\n",
      "\n",
      "    accuracy                           0.57      5984\n",
      "   macro avg       0.28      0.40      0.33      5984\n",
      "weighted avg       0.41      0.57      0.48      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 2, LR 6.816747482547211e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.261301  [   32/13961]\n",
      "loss: 1.092161  [ 3232/13961]\n",
      "loss: 1.082072  [ 6432/13961]\n",
      "loss: 1.129972  [ 9632/13961]\n",
      "loss: 1.173394  [12832/13961]\n",
      "time taken 1.081580638885498\n",
      "Test Scores: \n",
      " Accuracy: 57.8%, F1:33.4%,  Test loss: 1.160751, Training loss:1.151954 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.51      0.74      0.60      1739\n",
      "         3.0       0.63      0.87      0.73      2479\n",
      "\n",
      "    accuracy                           0.58      5984\n",
      "   macro avg       0.28      0.40      0.33      5984\n",
      "weighted avg       0.41      0.58      0.48      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 3, LR 6.906357545032103e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.134406  [   32/13961]\n",
      "loss: 1.133071  [ 3232/13961]\n",
      "loss: 1.022117  [ 6432/13961]\n",
      "loss: 1.034971  [ 9632/13961]\n",
      "loss: 1.196739  [12832/13961]\n",
      "time taken 1.1340670585632324\n",
      "Test Scores: \n",
      " Accuracy: 58.4%, F1:33.8%,  Test loss: 1.155995, Training loss:1.148880 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.52      0.76      0.61      1739\n",
      "         3.0       0.64      0.88      0.74      2479\n",
      "\n",
      "    accuracy                           0.58      5984\n",
      "   macro avg       0.29      0.41      0.34      5984\n",
      "weighted avg       0.41      0.58      0.48      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 4, LR 6.982406295893883e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.085823  [   32/13961]\n",
      "loss: 1.159975  [ 3232/13961]\n",
      "loss: 1.033198  [ 6432/13961]\n",
      "loss: 1.257466  [ 9632/13961]\n",
      "loss: 1.161836  [12832/13961]\n",
      "time taken 1.063333511352539\n",
      "Test Scores: \n",
      " Accuracy: 58.7%, F1:33.9%,  Test loss: 1.151516, Training loss:1.144899 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.52      0.76      0.62      1739\n",
      "         3.0       0.64      0.88      0.74      2479\n",
      "\n",
      "    accuracy                           0.59      5984\n",
      "   macro avg       0.29      0.41      0.34      5984\n",
      "weighted avg       0.42      0.59      0.49      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 5, LR 7.054782844222977e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.265118  [   32/13961]\n",
      "loss: 1.000384  [ 3232/13961]\n",
      "loss: 1.087025  [ 6432/13961]\n",
      "loss: 1.120154  [ 9632/13961]\n",
      "loss: 1.145818  [12832/13961]\n",
      "time taken 1.1328256130218506\n",
      "Test Scores: \n",
      " Accuracy: 59.1%, F1:34.2%,  Test loss: 1.148564, Training loss:1.139915 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.53      0.77      0.63      1739\n",
      "         3.0       0.63      0.89      0.74      2479\n",
      "\n",
      "    accuracy                           0.59      5984\n",
      "   macro avg       0.29      0.41      0.34      5984\n",
      "weighted avg       0.42      0.59      0.49      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 6, LR 7.102900033441998e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.055109  [   32/13961]\n",
      "loss: 1.045949  [ 3232/13961]\n",
      "loss: 1.133061  [ 6432/13961]\n",
      "loss: 1.181074  [ 9632/13961]\n",
      "loss: 1.049631  [12832/13961]\n",
      "time taken 0.9594752788543701\n",
      "Test Scores: \n",
      " Accuracy: 59.1%, F1:34.2%,  Test loss: 1.145632, Training loss:1.137145 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.53      0.78      0.63      1739\n",
      "         3.0       0.64      0.88      0.74      2479\n",
      "\n",
      "    accuracy                           0.59      5984\n",
      "   macro avg       0.29      0.41      0.34      5984\n",
      "weighted avg       0.42      0.59      0.49      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 7, LR 7.151025974212467e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.257278  [   32/13961]\n",
      "loss: 1.030462  [ 3232/13961]\n",
      "loss: 1.209325  [ 6432/13961]\n",
      "loss: 1.135936  [ 9632/13961]\n",
      "loss: 1.038262  [12832/13961]\n",
      "time taken 1.0078086853027344\n",
      "Test Scores: \n",
      " Accuracy: 59.3%, F1:34.3%,  Test loss: 1.143359, Training loss:1.134391 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.53      0.78      0.63      1739\n",
      "         3.0       0.64      0.89      0.74      2479\n",
      "\n",
      "    accuracy                           0.59      5984\n",
      "   macro avg       0.29      0.42      0.34      5984\n",
      "weighted avg       0.42      0.59      0.49      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 8, LR 7.188541550808467e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.043333  [   32/13961]\n",
      "loss: 1.086503  [ 3232/13961]\n",
      "loss: 1.085157  [ 6432/13961]\n",
      "loss: 1.227872  [ 9632/13961]\n",
      "loss: 1.019265  [12832/13961]\n",
      "time taken 0.9524765014648438\n",
      "Test Scores: \n",
      " Accuracy: 59.8%, F1:34.7%,  Test loss: 1.139904, Training loss:1.131590 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.53      0.80      0.64      1739\n",
      "         3.0       0.65      0.89      0.75      2479\n",
      "\n",
      "    accuracy                           0.60      5984\n",
      "   macro avg       0.30      0.42      0.35      5984\n",
      "weighted avg       0.42      0.60      0.50      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 9, LR 7.24595754741607e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.109635  [   32/13961]\n",
      "loss: 1.089153  [ 3232/13961]\n",
      "loss: 1.128159  [ 6432/13961]\n",
      "loss: 1.216460  [ 9632/13961]\n",
      "loss: 1.257572  [12832/13961]\n",
      "time taken 0.9514961242675781\n",
      "Test Scores: \n",
      " Accuracy: 59.7%, F1:34.6%,  Test loss: 1.138771, Training loss:1.127113 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.53      0.80      0.64      1739\n",
      "         3.0       0.65      0.88      0.75      2479\n",
      "\n",
      "    accuracy                           0.60      5984\n",
      "   macro avg       0.29      0.42      0.35      5984\n",
      "weighted avg       0.42      0.60      0.50      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 10, LR 7.264891243379332e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.046249  [   32/13961]\n",
      "loss: 1.222543  [ 3232/13961]\n",
      "loss: 1.140337  [ 6432/13961]\n",
      "loss: 1.153048  [ 9632/13961]\n",
      "loss: 1.095136  [12832/13961]\n",
      "time taken 1.23512864112854\n",
      "Test Scores: \n",
      " Accuracy: 60.0%, F1:34.7%,  Test loss: 1.136068, Training loss:1.125195 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.54      0.79      0.64      1739\n",
      "         3.0       0.64      0.89      0.75      2479\n",
      "\n",
      "    accuracy                           0.60      5984\n",
      "   macro avg       0.30      0.42      0.35      5984\n",
      "weighted avg       0.42      0.60      0.50      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 11, LR 7.310250549977783e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.146024  [   32/13961]\n",
      "loss: 1.052971  [ 3232/13961]\n",
      "loss: 1.128450  [ 6432/13961]\n",
      "loss: 1.200572  [ 9632/13961]\n",
      "loss: 1.221236  [12832/13961]\n",
      "time taken 0.927274227142334\n",
      "Test Scores: \n",
      " Accuracy: 59.9%, F1:34.7%,  Test loss: 1.132885, Training loss:1.122161 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.00      0.00      0.00      1214\n",
      "         2.0       0.54      0.79      0.64      1739\n",
      "         3.0       0.64      0.89      0.75      2479\n",
      "\n",
      "    accuracy                           0.60      5984\n",
      "   macro avg       0.30      0.42      0.35      5984\n",
      "weighted avg       0.42      0.60      0.50      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 12, LR 7.364014642235936e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.082093  [   32/13961]\n",
      "loss: 1.073577  [ 3232/13961]\n",
      "loss: 1.037235  [ 6432/13961]\n",
      "loss: 1.079188  [ 9632/13961]\n",
      "loss: 1.080238  [12832/13961]\n",
      "time taken 0.93355393409729\n",
      "Test Scores: \n",
      " Accuracy: 60.3%, F1:35.1%,  Test loss: 1.129517, Training loss:1.120399 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.60      0.00      0.00      1214\n",
      "         2.0       0.55      0.80      0.65      1739\n",
      "         3.0       0.64      0.90      0.75      2479\n",
      "\n",
      "    accuracy                           0.60      5984\n",
      "   macro avg       0.45      0.42      0.35      5984\n",
      "weighted avg       0.55      0.60      0.50      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 13, LR 7.421358535334886e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.113249  [   32/13961]\n",
      "loss: 1.123683  [ 3232/13961]\n",
      "loss: 1.308925  [ 6432/13961]\n",
      "loss: 1.197962  [ 9632/13961]\n",
      "loss: 1.047992  [12832/13961]\n",
      "time taken 0.95890212059021\n",
      "Test Scores: \n",
      " Accuracy: 60.8%, F1:35.4%,  Test loss: 1.128755, Training loss:1.118317 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.57      0.00      0.01      1214\n",
      "         2.0       0.55      0.80      0.66      1739\n",
      "         3.0       0.65      0.90      0.75      2479\n",
      "\n",
      "    accuracy                           0.61      5984\n",
      "   macro avg       0.44      0.43      0.35      5984\n",
      "weighted avg       0.55      0.61      0.50      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 14, LR 7.434380646828425e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.097700  [   32/13961]\n",
      "loss: 1.098444  [ 3232/13961]\n",
      "loss: 1.062168  [ 6432/13961]\n",
      "loss: 1.116243  [ 9632/13961]\n",
      "loss: 1.083875  [12832/13961]\n",
      "time taken 0.9168825149536133\n",
      "Test Scores: \n",
      " Accuracy: 60.7%, F1:35.5%,  Test loss: 1.125714, Training loss:1.115369 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.50      0.01      0.01      1214\n",
      "         2.0       0.55      0.81      0.65      1739\n",
      "         3.0       0.65      0.90      0.75      2479\n",
      "\n",
      "    accuracy                           0.61      5984\n",
      "   macro avg       0.43      0.43      0.35      5984\n",
      "weighted avg       0.53      0.61      0.50      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 15, LR 7.486616367095123e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.153902  [   32/13961]\n",
      "loss: 1.156318  [ 3232/13961]\n",
      "loss: 1.042130  [ 6432/13961]\n",
      "loss: 1.150662  [ 9632/13961]\n",
      "loss: 1.227651  [12832/13961]\n",
      "time taken 0.9423730373382568\n",
      "Test Scores: \n",
      " Accuracy: 61.1%, F1:36.2%,  Test loss: 1.123660, Training loss:1.114824 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.66      0.02      0.03      1214\n",
      "         2.0       0.55      0.81      0.66      1739\n",
      "         3.0       0.66      0.90      0.76      2479\n",
      "\n",
      "    accuracy                           0.61      5984\n",
      "   macro avg       0.47      0.43      0.36      5984\n",
      "weighted avg       0.57      0.61      0.51      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 16, LR 7.522107073847545e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.031070  [   32/13961]\n",
      "loss: 1.151551  [ 3232/13961]\n",
      "loss: 1.133689  [ 6432/13961]\n",
      "loss: 1.264424  [ 9632/13961]\n",
      "loss: 1.053487  [12832/13961]\n",
      "time taken 0.9604580402374268\n",
      "Test Scores: \n",
      " Accuracy: 61.4%, F1:37.0%,  Test loss: 1.120141, Training loss:1.110473 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.00      0.00       552\n",
      "         1.0       0.57      0.03      0.06      1214\n",
      "         2.0       0.57      0.79      0.66      1739\n",
      "         3.0       0.65      0.91      0.76      2479\n",
      "\n",
      "    accuracy                           0.61      5984\n",
      "   macro avg       0.53      0.43      0.37      5984\n",
      "weighted avg       0.58      0.61      0.52      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 17, LR 7.583319890374992e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.085461  [   32/13961]\n",
      "loss: 1.136575  [ 3232/13961]\n",
      "loss: 1.183754  [ 6432/13961]\n",
      "loss: 1.107026  [ 9632/13961]\n",
      "loss: 1.017856  [12832/13961]\n",
      "time taken 0.934910774230957\n",
      "Test Scores: \n",
      " Accuracy: 61.5%, F1:37.3%,  Test loss: 1.119521, Training loss:1.109007 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.53      0.04      0.07      1214\n",
      "         2.0       0.56      0.81      0.66      1739\n",
      "         3.0       0.66      0.90      0.76      2479\n",
      "\n",
      "    accuracy                           0.62      5984\n",
      "   macro avg       0.44      0.44      0.37      5984\n",
      "weighted avg       0.54      0.62      0.52      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 18, LR 7.594148036399622e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.243588  [   32/13961]\n",
      "loss: 1.154542  [ 3232/13961]\n",
      "loss: 1.135198  [ 6432/13961]\n",
      "loss: 0.991178  [ 9632/13961]\n",
      "loss: 1.207581  [12832/13961]\n",
      "time taken 0.9694337844848633\n",
      "Test Scores: \n",
      " Accuracy: 61.5%, F1:38.5%,  Test loss: 1.118302, Training loss:1.104753 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.52      0.07      0.12      1214\n",
      "         2.0       0.57      0.81      0.66      1739\n",
      "         3.0       0.66      0.89      0.76      2479\n",
      "\n",
      "    accuracy                           0.62      5984\n",
      "   macro avg       0.43      0.44      0.38      5984\n",
      "weighted avg       0.54      0.62      0.53      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 19, LR 7.615484083828908e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.102555  [   32/13961]\n",
      "loss: 1.064387  [ 3232/13961]\n",
      "loss: 1.221967  [ 6432/13961]\n",
      "loss: 1.034610  [ 9632/13961]\n",
      "loss: 1.177124  [12832/13961]\n",
      "time taken 0.9429101943969727\n",
      "Test Scores: \n",
      " Accuracy: 62.3%, F1:40.2%,  Test loss: 1.112584, Training loss:1.102370 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.00      0.01       552\n",
      "         1.0       0.58      0.10      0.17      1214\n",
      "         2.0       0.58      0.80      0.67      1739\n",
      "         3.0       0.66      0.90      0.76      2479\n",
      "\n",
      "    accuracy                           0.62      5984\n",
      "   macro avg       0.55      0.45      0.40      5984\n",
      "weighted avg       0.59      0.62      0.54      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 20, LR 7.716427365815478e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.216240  [   32/13961]\n",
      "loss: 1.108981  [ 3232/13961]\n",
      "loss: 1.190049  [ 6432/13961]\n",
      "loss: 1.168085  [ 9632/13961]\n",
      "loss: 1.061828  [12832/13961]\n",
      "time taken 0.9877407550811768\n",
      "Test Scores: \n",
      " Accuracy: 62.5%, F1:41.1%,  Test loss: 1.111207, Training loss:1.097385 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.00      0.01       552\n",
      "         1.0       0.52      0.13      0.21      1214\n",
      "         2.0       0.57      0.80      0.67      1739\n",
      "         3.0       0.67      0.88      0.76      2479\n",
      "\n",
      "    accuracy                           0.62      5984\n",
      "   macro avg       0.54      0.45      0.41      5984\n",
      "weighted avg       0.59      0.62      0.55      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 21, LR 7.740936259955943e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.087967  [   32/13961]\n",
      "loss: 1.096294  [ 3232/13961]\n",
      "loss: 1.017687  [ 6432/13961]\n",
      "loss: 1.093987  [ 9632/13961]\n",
      "loss: 1.084068  [12832/13961]\n",
      "time taken 0.9628159999847412\n",
      "Test Scores: \n",
      " Accuracy: 63.7%, F1:43.5%,  Test loss: 1.104352, Training loss:1.093807 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.52      0.20      0.29      1214\n",
      "         2.0       0.60      0.78      0.68      1739\n",
      "         3.0       0.68      0.90      0.77      2479\n",
      "\n",
      "    accuracy                           0.64      5984\n",
      "   macro avg       0.45      0.47      0.43      5984\n",
      "weighted avg       0.56      0.64      0.58      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 22, LR 7.864072867763575e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.189487  [   32/13961]\n",
      "loss: 1.143668  [ 3232/13961]\n",
      "loss: 1.094730  [ 6432/13961]\n",
      "loss: 1.071714  [ 9632/13961]\n",
      "loss: 1.104371  [12832/13961]\n",
      "time taken 0.9273476600646973\n",
      "Test Scores: \n",
      " Accuracy: 64.0%, F1:44.7%,  Test loss: 1.100812, Training loss:1.088887 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.00      0.01       552\n",
      "         1.0       0.52      0.24      0.33      1214\n",
      "         2.0       0.61      0.78      0.68      1739\n",
      "         3.0       0.68      0.88      0.77      2479\n",
      "\n",
      "    accuracy                           0.64      5984\n",
      "   macro avg       0.58      0.48      0.45      5984\n",
      "weighted avg       0.61      0.64      0.58      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 23, LR 7.928452139167602e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.222129  [   32/13961]\n",
      "loss: 0.895051  [ 3232/13961]\n",
      "loss: 1.114288  [ 6432/13961]\n",
      "loss: 1.079777  [ 9632/13961]\n",
      "loss: 1.084009  [12832/13961]\n",
      "time taken 0.9426009654998779\n",
      "Test Scores: \n",
      " Accuracy: 64.1%, F1:44.9%,  Test loss: 1.099122, Training loss:1.084984 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.52      0.25      0.34      1214\n",
      "         2.0       0.61      0.78      0.69      1739\n",
      "         3.0       0.69      0.88      0.77      2479\n",
      "\n",
      "    accuracy                           0.64      5984\n",
      "   macro avg       0.45      0.48      0.45      5984\n",
      "weighted avg       0.57      0.64      0.59      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 24, LR 7.959348336122115e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.112932  [   32/13961]\n",
      "loss: 1.127550  [ 3232/13961]\n",
      "loss: 1.122739  [ 6432/13961]\n",
      "loss: 1.216452  [ 9632/13961]\n",
      "loss: 1.153230  [12832/13961]\n",
      "time taken 0.90574049949646\n",
      "Test Scores: \n",
      " Accuracy: 65.1%, F1:46.7%,  Test loss: 1.092513, Training loss:1.077470 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.00      0.01       552\n",
      "         1.0       0.54      0.31      0.40      1214\n",
      "         2.0       0.63      0.78      0.69      1739\n",
      "         3.0       0.69      0.87      0.77      2479\n",
      "\n",
      "    accuracy                           0.65      5984\n",
      "   macro avg       0.59      0.49      0.47      5984\n",
      "weighted avg       0.63      0.65      0.60      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 25, LR 8.081399630809328e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.989817  [   32/13961]\n",
      "loss: 0.994333  [ 3232/13961]\n",
      "loss: 1.055782  [ 6432/13961]\n",
      "loss: 1.036277  [ 9632/13961]\n",
      "loss: 1.130398  [12832/13961]\n",
      "time taken 0.9594748020172119\n",
      "Test Scores: \n",
      " Accuracy: 65.6%, F1:47.4%,  Test loss: 1.087081, Training loss:1.073930 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.55      0.35      0.43      1214\n",
      "         2.0       0.63      0.76      0.69      1739\n",
      "         3.0       0.70      0.88      0.78      2479\n",
      "\n",
      "    accuracy                           0.66      5984\n",
      "   macro avg       0.47      0.50      0.47      5984\n",
      "weighted avg       0.58      0.66      0.61      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 26, LR 8.183114732979535e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.126251  [   32/13961]\n",
      "loss: 1.079064  [ 3232/13961]\n",
      "loss: 1.092520  [ 6432/13961]\n",
      "loss: 1.081643  [ 9632/13961]\n",
      "loss: 1.086439  [12832/13961]\n",
      "time taken 0.9866354465484619\n",
      "Test Scores: \n",
      " Accuracy: 66.1%, F1:47.9%,  Test loss: 1.082557, Training loss:1.066961 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.56      0.37      0.44      1214\n",
      "         2.0       0.64      0.76      0.69      1739\n",
      "         3.0       0.70      0.88      0.78      2479\n",
      "\n",
      "    accuracy                           0.66      5984\n",
      "   macro avg       0.47      0.50      0.48      5984\n",
      "weighted avg       0.59      0.66      0.62      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 27, LR 8.26881904742918e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.045648  [   32/13961]\n",
      "loss: 1.089808  [ 3232/13961]\n",
      "loss: 1.062939  [ 6432/13961]\n",
      "loss: 1.033883  [ 9632/13961]\n",
      "loss: 1.220923  [12832/13961]\n",
      "time taken 0.9184708595275879\n",
      "Test Scores: \n",
      " Accuracy: 66.6%, F1:48.8%,  Test loss: 1.078135, Training loss:1.064102 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.56      0.40      0.46      1214\n",
      "         2.0       0.65      0.77      0.70      1739\n",
      "         3.0       0.71      0.87      0.78      2479\n",
      "\n",
      "    accuracy                           0.67      5984\n",
      "   macro avg       0.48      0.51      0.49      5984\n",
      "weighted avg       0.60      0.67      0.62      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 28, LR 8.353435994101372e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.080627  [   32/13961]\n",
      "loss: 1.127263  [ 3232/13961]\n",
      "loss: 0.982572  [ 6432/13961]\n",
      "loss: 1.064175  [ 9632/13961]\n",
      "loss: 1.112707  [12832/13961]\n",
      "time taken 0.9652299880981445\n",
      "Test Scores: \n",
      " Accuracy: 66.7%, F1:48.9%,  Test loss: 1.075608, Training loss:1.060409 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.57      0.41      0.48      1214\n",
      "         2.0       0.64      0.76      0.70      1739\n",
      "         3.0       0.71      0.87      0.78      2479\n",
      "\n",
      "    accuracy                           0.67      5984\n",
      "   macro avg       0.48      0.51      0.49      5984\n",
      "weighted avg       0.60      0.67      0.62      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 29, LR 8.402185147517229e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.130670  [   32/13961]\n",
      "loss: 1.026810  [ 3232/13961]\n",
      "loss: 1.015925  [ 6432/13961]\n",
      "loss: 1.049475  [ 9632/13961]\n",
      "loss: 1.054831  [12832/13961]\n",
      "time taken 0.9005928039550781\n",
      "Test Scores: \n",
      " Accuracy: 67.9%, F1:50.5%,  Test loss: 1.067340, Training loss:1.053681 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.59      0.47      0.52      1214\n",
      "         2.0       0.65      0.77      0.71      1739\n",
      "         3.0       0.73      0.87      0.79      2479\n",
      "\n",
      "    accuracy                           0.68      5984\n",
      "   macro avg       0.49      0.53      0.51      5984\n",
      "weighted avg       0.61      0.68      0.64      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 30, LR 8.563663418171085e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.139909  [   32/13961]\n",
      "loss: 1.100116  [ 3232/13961]\n",
      "loss: 1.132572  [ 6432/13961]\n",
      "loss: 1.079773  [ 9632/13961]\n",
      "loss: 1.064466  [12832/13961]\n",
      "time taken 0.9602651596069336\n",
      "Test Scores: \n",
      " Accuracy: 68.1%, F1:50.8%,  Test loss: 1.062222, Training loss:1.048566 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00       552\n",
      "         1.0       0.59      0.47      0.52      1214\n",
      "         2.0       0.66      0.77      0.71      1739\n",
      "         3.0       0.72      0.87      0.79      2479\n",
      "\n",
      "    accuracy                           0.68      5984\n",
      "   macro avg       0.74      0.53      0.51      5984\n",
      "weighted avg       0.70      0.68      0.64      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 31, LR 8.665194895425182e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.050542  [   32/13961]\n",
      "loss: 1.040016  [ 3232/13961]\n",
      "loss: 0.979662  [ 6432/13961]\n",
      "loss: 1.039316  [ 9632/13961]\n",
      "loss: 1.118921  [12832/13961]\n",
      "time taken 0.9105651378631592\n",
      "Test Scores: \n",
      " Accuracy: 68.2%, F1:51.1%,  Test loss: 1.061227, Training loss:1.045169 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.60      0.50      0.54      1214\n",
      "         2.0       0.66      0.77      0.71      1739\n",
      "         3.0       0.72      0.86      0.79      2479\n",
      "\n",
      "    accuracy                           0.68      5984\n",
      "   macro avg       0.50      0.53      0.51      5984\n",
      "weighted avg       0.61      0.68      0.64      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 32, LR 8.685060172179751e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.033572  [   32/13961]\n",
      "loss: 1.055171  [ 3232/13961]\n",
      "loss: 1.061251  [ 6432/13961]\n",
      "loss: 1.136708  [ 9632/13961]\n",
      "loss: 1.145343  [12832/13961]\n",
      "time taken 0.9122946262359619\n",
      "Test Scores: \n",
      " Accuracy: 68.5%, F1:51.3%,  Test loss: 1.057294, Training loss:1.041645 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.59      0.51      0.55      1214\n",
      "         2.0       0.68      0.76      0.72      1739\n",
      "         3.0       0.72      0.87      0.79      2479\n",
      "\n",
      "    accuracy                           0.69      5984\n",
      "   macro avg       0.50      0.53      0.51      5984\n",
      "weighted avg       0.62      0.69      0.65      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 33, LR 8.764063878961714e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.982139  [   32/13961]\n",
      "loss: 1.160019  [ 3232/13961]\n",
      "loss: 1.150022  [ 6432/13961]\n",
      "loss: 0.902387  [ 9632/13961]\n",
      "loss: 1.005141  [12832/13961]\n",
      "time taken 0.931981086730957\n",
      "Test Scores: \n",
      " Accuracy: 68.9%, F1:51.9%,  Test loss: 1.053864, Training loss:1.039082 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.61      0.54      0.57      1214\n",
      "         2.0       0.67      0.76      0.71      1739\n",
      "         3.0       0.73      0.86      0.79      2479\n",
      "\n",
      "    accuracy                           0.69      5984\n",
      "   macro avg       0.50      0.54      0.52      5984\n",
      "weighted avg       0.62      0.69      0.65      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 34, LR 8.833562572696464e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.937534  [   32/13961]\n",
      "loss: 1.044909  [ 3232/13961]\n",
      "loss: 0.945046  [ 6432/13961]\n",
      "loss: 1.046214  [ 9632/13961]\n",
      "loss: 1.127131  [12832/13961]\n",
      "time taken 0.8909308910369873\n",
      "Test Scores: \n",
      " Accuracy: 69.4%, F1:52.4%,  Test loss: 1.048422, Training loss:1.035068 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.62      0.56      0.59      1214\n",
      "         2.0       0.67      0.76      0.71      1739\n",
      "         3.0       0.74      0.87      0.80      2479\n",
      "\n",
      "    accuracy                           0.69      5984\n",
      "   macro avg       0.51      0.55      0.52      5984\n",
      "weighted avg       0.63      0.69      0.66      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 35, LR 8.944956712363588e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.095911  [   32/13961]\n",
      "loss: 1.033792  [ 3232/13961]\n",
      "loss: 0.983911  [ 6432/13961]\n",
      "loss: 1.058048  [ 9632/13961]\n",
      "loss: 1.096779  [12832/13961]\n",
      "time taken 0.9229004383087158\n",
      "Test Scores: \n",
      " Accuracy: 69.5%, F1:52.6%,  Test loss: 1.046410, Training loss:1.031437 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.62      0.56      0.59      1214\n",
      "         2.0       0.68      0.77      0.72      1739\n",
      "         3.0       0.73      0.87      0.79      2479\n",
      "\n",
      "    accuracy                           0.70      5984\n",
      "   macro avg       0.51      0.55      0.53      5984\n",
      "weighted avg       0.63      0.70      0.66      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 36, LR 8.986488588377357e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.023426  [   32/13961]\n",
      "loss: 0.934528  [ 3232/13961]\n",
      "loss: 1.057056  [ 6432/13961]\n",
      "loss: 1.010979  [ 9632/13961]\n",
      "loss: 0.945343  [12832/13961]\n",
      "time taken 0.924612283706665\n",
      "Test Scores: \n",
      " Accuracy: 70.0%, F1:53.2%,  Test loss: 1.043650, Training loss:1.028774 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.63      0.59      0.61      1214\n",
      "         2.0       0.67      0.78      0.72      1739\n",
      "         3.0       0.75      0.85      0.80      2479\n",
      "\n",
      "    accuracy                           0.70      5984\n",
      "   macro avg       0.51      0.56      0.53      5984\n",
      "weighted avg       0.63      0.70      0.66      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 37, LR 9.043789416216236e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.934587  [   32/13961]\n",
      "loss: 0.950175  [ 3232/13961]\n",
      "loss: 1.067699  [ 6432/13961]\n",
      "loss: 1.061168  [ 9632/13961]\n",
      "loss: 1.139420  [12832/13961]\n",
      "time taken 0.9241986274719238\n",
      "Test Scores: \n",
      " Accuracy: 69.6%, F1:52.6%,  Test loss: 1.044833, Training loss:1.025172 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.62      0.56      0.59      1214\n",
      "         2.0       0.68      0.77      0.72      1739\n",
      "         3.0       0.74      0.87      0.80      2479\n",
      "\n",
      "    accuracy                           0.70      5984\n",
      "   macro avg       0.51      0.55      0.53      5984\n",
      "weighted avg       0.63      0.70      0.66      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 38, LR 9.019172124154078e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.951111  [   32/13961]\n",
      "loss: 1.071959  [ 3232/13961]\n",
      "loss: 0.945850  [ 6432/13961]\n",
      "loss: 0.975273  [ 9632/13961]\n",
      "loss: 1.075099  [12832/13961]\n",
      "time taken 0.9764852523803711\n",
      "Test Scores: \n",
      " Accuracy: 69.6%, F1:52.8%,  Test loss: 1.043727, Training loss:1.022006 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.63      0.58      0.60      1214\n",
      "         2.0       0.67      0.77      0.72      1739\n",
      "         3.0       0.74      0.86      0.80      2479\n",
      "\n",
      "    accuracy                           0.70      5984\n",
      "   macro avg       0.51      0.55      0.53      5984\n",
      "weighted avg       0.63      0.70      0.66      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 39, LR 9.042172340218832e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.945627  [   32/13961]\n",
      "loss: 0.959587  [ 3232/13961]\n",
      "loss: 0.970283  [ 6432/13961]\n",
      "loss: 0.999575  [ 9632/13961]\n",
      "loss: 1.007584  [12832/13961]\n",
      "time taken 0.9493844509124756\n",
      "Test Scores: \n",
      " Accuracy: 70.3%, F1:53.4%,  Test loss: 1.039038, Training loss:1.021253 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.63      0.60      0.61      1214\n",
      "         2.0       0.68      0.77      0.72      1739\n",
      "         3.0       0.75      0.86      0.80      2479\n",
      "\n",
      "    accuracy                           0.70      5984\n",
      "   macro avg       0.51      0.56      0.53      5984\n",
      "weighted avg       0.64      0.70      0.67      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 40, LR 9.140334120667189e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.125625  [   32/13961]\n",
      "loss: 1.067916  [ 3232/13961]\n",
      "loss: 1.028683  [ 6432/13961]\n",
      "loss: 1.052664  [ 9632/13961]\n",
      "loss: 1.069315  [12832/13961]\n",
      "time taken 0.9997375011444092\n",
      "Test Scores: \n",
      " Accuracy: 70.7%, F1:54.1%,  Test loss: 1.035320, Training loss:1.019555 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.65      0.63      0.64      1214\n",
      "         2.0       0.68      0.78      0.72      1739\n",
      "         3.0       0.75      0.86      0.80      2479\n",
      "\n",
      "    accuracy                           0.71      5984\n",
      "   macro avg       0.52      0.56      0.54      5984\n",
      "weighted avg       0.64      0.71      0.67      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 41, LR 9.218928174480519e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.087073  [   32/13961]\n",
      "loss: 1.112910  [ 3232/13961]\n",
      "loss: 0.989575  [ 6432/13961]\n",
      "loss: 1.018339  [ 9632/13961]\n",
      "loss: 0.920472  [12832/13961]\n",
      "time taken 0.9696078300476074\n",
      "Test Scores: \n",
      " Accuracy: 70.4%, F1:53.8%,  Test loss: 1.037675, Training loss:1.015678 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.63      0.62      0.63      1214\n",
      "         2.0       0.67      0.77      0.72      1739\n",
      "         3.0       0.76      0.85      0.80      2479\n",
      "\n",
      "    accuracy                           0.70      5984\n",
      "   macro avg       0.52      0.56      0.54      5984\n",
      "weighted avg       0.64      0.70      0.67      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 42, LR 9.169056306171443e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.017861  [   32/13961]\n",
      "loss: 1.013023  [ 3232/13961]\n",
      "loss: 1.032929  [ 6432/13961]\n",
      "loss: 0.942334  [ 9632/13961]\n",
      "loss: 1.023108  [12832/13961]\n",
      "time taken 0.950676441192627\n",
      "Test Scores: \n",
      " Accuracy: 70.4%, F1:53.9%,  Test loss: 1.035122, Training loss:1.014486 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.65      0.63      0.64      1214\n",
      "         2.0       0.67      0.79      0.72      1739\n",
      "         3.0       0.76      0.84      0.80      2479\n",
      "\n",
      "    accuracy                           0.70      5984\n",
      "   macro avg       0.52      0.56      0.54      5984\n",
      "weighted avg       0.64      0.70      0.67      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 43, LR 9.223117372971431e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.037310  [   32/13961]\n",
      "loss: 0.969089  [ 3232/13961]\n",
      "loss: 0.963866  [ 6432/13961]\n",
      "loss: 1.148582  [ 9632/13961]\n",
      "loss: 1.083305  [12832/13961]\n",
      "time taken 1.01261568069458\n",
      "Test Scores: \n",
      " Accuracy: 71.0%, F1:54.3%,  Test loss: 1.031202, Training loss:1.011820 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.65      0.63      0.64      1214\n",
      "         2.0       0.68      0.79      0.73      1739\n",
      "         3.0       0.76      0.86      0.80      2479\n",
      "\n",
      "    accuracy                           0.71      5984\n",
      "   macro avg       0.52      0.57      0.54      5984\n",
      "weighted avg       0.64      0.71      0.67      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 44, LR 9.306753888336329e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.006129  [   32/13961]\n",
      "loss: 0.943620  [ 3232/13961]\n",
      "loss: 0.882930  [ 6432/13961]\n",
      "loss: 1.054127  [ 9632/13961]\n",
      "loss: 1.087084  [12832/13961]\n",
      "time taken 0.9120008945465088\n",
      "Test Scores: \n",
      " Accuracy: 71.1%, F1:54.5%,  Test loss: 1.030433, Training loss:1.010634 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.65      0.65      0.65      1214\n",
      "         2.0       0.68      0.78      0.73      1739\n",
      "         3.0       0.76      0.85      0.80      2479\n",
      "\n",
      "    accuracy                           0.71      5984\n",
      "   macro avg       0.52      0.57      0.55      5984\n",
      "weighted avg       0.64      0.71      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 45, LR 9.323232817393972e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.055921  [   32/13961]\n",
      "loss: 1.082791  [ 3232/13961]\n",
      "loss: 1.142781  [ 6432/13961]\n",
      "loss: 1.119602  [ 9632/13961]\n",
      "loss: 1.021180  [12832/13961]\n",
      "time taken 0.9614593982696533\n",
      "Test Scores: \n",
      " Accuracy: 71.2%, F1:54.5%,  Test loss: 1.028642, Training loss:1.008631 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.65      0.65      0.65      1214\n",
      "         2.0       0.69      0.78      0.73      1739\n",
      "         3.0       0.76      0.86      0.80      2479\n",
      "\n",
      "    accuracy                           0.71      5984\n",
      "   macro avg       0.52      0.57      0.55      5984\n",
      "weighted avg       0.64      0.71      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 46, LR 9.361776457608104e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.979354  [   32/13961]\n",
      "loss: 0.878697  [ 3232/13961]\n",
      "loss: 0.984542  [ 6432/13961]\n",
      "loss: 0.890948  [ 9632/13961]\n",
      "loss: 1.151490  [12832/13961]\n",
      "time taken 0.9368987083435059\n",
      "Test Scores: \n",
      " Accuracy: 71.2%, F1:54.6%,  Test loss: 1.028160, Training loss:1.007889 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.65      0.65      0.65      1214\n",
      "         2.0       0.69      0.78      0.73      1739\n",
      "         3.0       0.76      0.85      0.80      2479\n",
      "\n",
      "    accuracy                           0.71      5984\n",
      "   macro avg       0.52      0.57      0.55      5984\n",
      "weighted avg       0.65      0.71      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 47, LR 9.372156909474845e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.127171  [   32/13961]\n",
      "loss: 0.955464  [ 3232/13961]\n",
      "loss: 1.044163  [ 6432/13961]\n",
      "loss: 1.009094  [ 9632/13961]\n",
      "loss: 0.959376  [12832/13961]\n",
      "time taken 0.9030139446258545\n",
      "Test Scores: \n",
      " Accuracy: 71.8%, F1:55.2%,  Test loss: 1.024542, Training loss:1.008253 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00       552\n",
      "         1.0       0.67      0.65      0.66      1214\n",
      "         2.0       0.69      0.78      0.74      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.78      0.58      0.55      5984\n",
      "weighted avg       0.74      0.72      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 48, LR 9.450564174638936e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.074432  [   32/13961]\n",
      "loss: 1.094899  [ 3232/13961]\n",
      "loss: 1.014607  [ 6432/13961]\n",
      "loss: 0.955034  [ 9632/13961]\n",
      "loss: 0.986880  [12832/13961]\n",
      "time taken 0.9582419395446777\n",
      "Test Scores: \n",
      " Accuracy: 71.9%, F1:55.2%,  Test loss: 1.023554, Training loss:1.005860 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.68      0.66      0.67      1214\n",
      "         2.0       0.69      0.79      0.73      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.55      5984\n",
      "weighted avg       0.65      0.72      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 49, LR 9.472095267089471e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.030575  [   32/13961]\n",
      "loss: 1.108212  [ 3232/13961]\n",
      "loss: 1.076288  [ 6432/13961]\n",
      "loss: 1.064555  [ 9632/13961]\n",
      "loss: 0.984565  [12832/13961]\n",
      "time taken 0.9123213291168213\n",
      "Test Scores: \n",
      " Accuracy: 71.6%, F1:54.8%,  Test loss: 1.023829, Training loss:1.004107 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.67      0.65      0.66      1214\n",
      "         2.0       0.69      0.77      0.73      1739\n",
      "         3.0       0.75      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.57      0.55      5984\n",
      "weighted avg       0.65      0.72      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 50, LR 9.466105670047177e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.981192  [   32/13961]\n",
      "loss: 0.981257  [ 3232/13961]\n",
      "loss: 0.981200  [ 6432/13961]\n",
      "loss: 1.015739  [ 9632/13961]\n",
      "loss: 1.094627  [12832/13961]\n",
      "time taken 0.9125423431396484\n",
      "Test Scores: \n",
      " Accuracy: 71.8%, F1:55.1%,  Test loss: 1.022778, Training loss:1.003452 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.67      0.66      0.67      1214\n",
      "         2.0       0.69      0.78      0.73      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.55      5984\n",
      "weighted avg       0.65      0.72      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 51, LR 9.489029180988306e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.007304  [   32/13961]\n",
      "loss: 0.909126  [ 3232/13961]\n",
      "loss: 0.969637  [ 6432/13961]\n",
      "loss: 1.052107  [ 9632/13961]\n",
      "loss: 1.095057  [12832/13961]\n",
      "time taken 0.9461779594421387\n",
      "Test Scores: \n",
      " Accuracy: 71.8%, F1:55.2%,  Test loss: 1.022053, Training loss:1.001405 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.67      0.67      0.67      1214\n",
      "         2.0       0.69      0.77      0.73      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.55      5984\n",
      "weighted avg       0.65      0.72      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 52, LR 9.504895867518773e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.984613  [   32/13961]\n",
      "loss: 1.104397  [ 3232/13961]\n",
      "loss: 1.022269  [ 6432/13961]\n",
      "loss: 1.045058  [ 9632/13961]\n",
      "loss: 0.986821  [12832/13961]\n",
      "time taken 0.9126851558685303\n",
      "Test Scores: \n",
      " Accuracy: 72.4%, F1:55.6%,  Test loss: 1.018656, Training loss:1.002739 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.68      0.66      0.67      1214\n",
      "         2.0       0.70      0.79      0.74      1739\n",
      "         3.0       0.76      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.56      5984\n",
      "weighted avg       0.66      0.72      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 53, LR 9.579526164607828e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.051347  [   32/13961]\n",
      "loss: 0.951914  [ 3232/13961]\n",
      "loss: 1.009224  [ 6432/13961]\n",
      "loss: 0.980985  [ 9632/13961]\n",
      "loss: 1.127023  [12832/13961]\n",
      "time taken 1.0028090476989746\n",
      "Test Scores: \n",
      " Accuracy: 71.7%, F1:55.2%,  Test loss: 1.022155, Training loss:0.999634 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.67      0.67      0.67      1214\n",
      "         2.0       0.69      0.78      0.73      1739\n",
      "         3.0       0.76      0.85      0.80      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.55      5984\n",
      "weighted avg       0.65      0.72      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 54, LR 9.502664358006692e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.998952  [   32/13961]\n",
      "loss: 0.994803  [ 3232/13961]\n",
      "loss: 1.103426  [ 6432/13961]\n",
      "loss: 1.025227  [ 9632/13961]\n",
      "loss: 1.072576  [12832/13961]\n",
      "time taken 0.942368745803833\n",
      "Test Scores: \n",
      " Accuracy: 72.0%, F1:55.3%,  Test loss: 1.019649, Training loss:0.999644 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.67      0.67      0.67      1214\n",
      "         2.0       0.70      0.78      0.73      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.55      5984\n",
      "weighted avg       0.65      0.72      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 55, LR 9.557648890809506e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.003751  [   32/13961]\n",
      "loss: 1.011402  [ 3232/13961]\n",
      "loss: 0.866588  [ 6432/13961]\n",
      "loss: 0.972777  [ 9632/13961]\n",
      "loss: 0.875341  [12832/13961]\n",
      "time taken 0.9294004440307617\n",
      "Test Scores: \n",
      " Accuracy: 72.4%, F1:55.7%,  Test loss: 1.019037, Training loss:0.997385 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.68      0.68      0.68      1214\n",
      "         2.0       0.69      0.79      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.56      5984\n",
      "weighted avg       0.66      0.72      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 56, LR 9.571118530532194e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.030503  [   32/13961]\n",
      "loss: 1.123386  [ 3232/13961]\n",
      "loss: 1.006429  [ 6432/13961]\n",
      "loss: 0.933373  [ 9632/13961]\n",
      "loss: 0.974359  [12832/13961]\n",
      "time taken 0.9584813117980957\n",
      "Test Scores: \n",
      " Accuracy: 72.1%, F1:55.4%,  Test loss: 1.019445, Training loss:0.997180 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.67      0.68      0.67      1214\n",
      "         2.0       0.68      0.79      0.73      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.55      5984\n",
      "weighted avg       0.65      0.72      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 57, LR 9.562142590978675e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.959186  [   32/13961]\n",
      "loss: 0.942191  [ 3232/13961]\n",
      "loss: 0.966053  [ 6432/13961]\n",
      "loss: 0.993269  [ 9632/13961]\n",
      "loss: 0.955717  [12832/13961]\n",
      "time taken 0.9159305095672607\n",
      "Test Scores: \n",
      " Accuracy: 72.5%, F1:55.8%,  Test loss: 1.016219, Training loss:0.996111 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.68      0.68      0.68      1214\n",
      "         2.0       0.70      0.79      0.74      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.56      5984\n",
      "weighted avg       0.66      0.72      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 58, LR 9.633423785635412e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.874673  [   32/13961]\n",
      "loss: 1.031792  [ 3232/13961]\n",
      "loss: 0.976223  [ 6432/13961]\n",
      "loss: 1.038038  [ 9632/13961]\n",
      "loss: 1.022791  [12832/13961]\n",
      "time taken 0.9751875400543213\n",
      "Test Scores: \n",
      " Accuracy: 72.7%, F1:56.0%,  Test loss: 1.014890, Training loss:0.996775 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.70      0.68      0.69      1214\n",
      "         2.0       0.69      0.79      0.74      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 59, LR 9.662966703739862e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.988506  [   32/13961]\n",
      "loss: 1.027679  [ 3232/13961]\n",
      "loss: 0.983521  [ 6432/13961]\n",
      "loss: 0.962974  [ 9632/13961]\n",
      "loss: 0.984029  [12832/13961]\n",
      "time taken 0.9211397171020508\n",
      "Test Scores: \n",
      " Accuracy: 72.0%, F1:55.3%,  Test loss: 1.018873, Training loss:0.996434 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.68      0.67      0.67      1214\n",
      "         2.0       0.69      0.79      0.74      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.53      0.58      0.55      5984\n",
      "weighted avg       0.65      0.72      0.68      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 60, LR 9.574733534196922e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.042427  [   32/13961]\n",
      "loss: 0.922925  [ 3232/13961]\n",
      "loss: 1.001052  [ 6432/13961]\n",
      "loss: 1.011499  [ 9632/13961]\n",
      "loss: 1.017979  [12832/13961]\n",
      "time taken 0.9475955963134766\n",
      "Test Scores: \n",
      " Accuracy: 72.5%, F1:55.8%,  Test loss: 1.014296, Training loss:0.993886 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.68      0.68      0.68      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.58      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 61, LR 9.676175258519782e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.921776  [   32/13961]\n",
      "loss: 1.041936  [ 3232/13961]\n",
      "loss: 0.937980  [ 6432/13961]\n",
      "loss: 1.005671  [ 9632/13961]\n",
      "loss: 0.861297  [12832/13961]\n",
      "time taken 0.9673819541931152\n",
      "Test Scores: \n",
      " Accuracy: 72.4%, F1:55.8%,  Test loss: 1.014554, Training loss:0.995324 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.69      0.69      0.69      1214\n",
      "         2.0       0.69      0.79      0.74      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.72      5984\n",
      "   macro avg       0.54      0.58      0.56      5984\n",
      "weighted avg       0.66      0.72      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 62, LR 9.670427935522095e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.002148  [   32/13961]\n",
      "loss: 1.094106  [ 3232/13961]\n",
      "loss: 1.134217  [ 6432/13961]\n",
      "loss: 0.996471  [ 9632/13961]\n",
      "loss: 0.942531  [12832/13961]\n",
      "time taken 0.9274170398712158\n",
      "Test Scores: \n",
      " Accuracy: 72.6%, F1:56.0%,  Test loss: 1.014425, Training loss:0.994077 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.70      0.69      0.69      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 63, LR 9.673310829079321e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.859119  [   32/13961]\n",
      "loss: 0.878283  [ 3232/13961]\n",
      "loss: 1.114059  [ 6432/13961]\n",
      "loss: 1.061609  [ 9632/13961]\n",
      "loss: 0.967136  [12832/13961]\n",
      "time taken 0.9384341239929199\n",
      "Test Scores: \n",
      " Accuracy: 72.7%, F1:56.0%,  Test loss: 1.012726, Training loss:0.991451 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.70      0.68      0.69      1214\n",
      "         2.0       0.70      0.79      0.74      1739\n",
      "         3.0       0.76      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.58      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 64, LR 9.711232287991648e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.964503  [   32/13961]\n",
      "loss: 1.025092  [ 3232/13961]\n",
      "loss: 0.946155  [ 6432/13961]\n",
      "loss: 1.079477  [ 9632/13961]\n",
      "loss: 0.987914  [12832/13961]\n",
      "time taken 0.9650111198425293\n",
      "Test Scores: \n",
      " Accuracy: 72.7%, F1:56.1%,  Test loss: 1.013778, Training loss:0.992463 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.69      0.69      0.69      1214\n",
      "         2.0       0.69      0.79      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 65, LR 9.68771900329145e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.096563  [   32/13961]\n",
      "loss: 0.974725  [ 3232/13961]\n",
      "loss: 1.149157  [ 6432/13961]\n",
      "loss: 1.073574  [ 9632/13961]\n",
      "loss: 1.099942  [12832/13961]\n",
      "time taken 0.9523305892944336\n",
      "Test Scores: \n",
      " Accuracy: 72.8%, F1:56.1%,  Test loss: 1.013549, Training loss:0.991736 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.70      0.69      0.69      1214\n",
      "         2.0       0.69      0.79      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 66, LR 9.692847261415256e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.909950  [   32/13961]\n",
      "loss: 0.963864  [ 3232/13961]\n",
      "loss: 0.841042  [ 6432/13961]\n",
      "loss: 1.032149  [ 9632/13961]\n",
      "loss: 0.965616  [12832/13961]\n",
      "time taken 0.935499906539917\n",
      "Test Scores: \n",
      " Accuracy: 73.0%, F1:56.3%,  Test loss: 1.010910, Training loss:0.989631 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.69      0.69      0.69      1214\n",
      "         2.0       0.71      0.79      0.74      1739\n",
      "         3.0       0.76      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 67, LR 9.751913267024313e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.969431  [   32/13961]\n",
      "loss: 0.948397  [ 3232/13961]\n",
      "loss: 0.950358  [ 6432/13961]\n",
      "loss: 0.907001  [ 9632/13961]\n",
      "loss: 1.060270  [12832/13961]\n",
      "time taken 0.9118568897247314\n",
      "Test Scores: \n",
      " Accuracy: 73.0%, F1:56.3%,  Test loss: 1.013030, Training loss:0.990039 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.69      0.70      1214\n",
      "         2.0       0.70      0.79      0.74      1739\n",
      "         3.0       0.76      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 68, LR 9.704436102035376e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.000263  [   32/13961]\n",
      "loss: 1.178502  [ 3232/13961]\n",
      "loss: 1.022346  [ 6432/13961]\n",
      "loss: 0.993317  [ 9632/13961]\n",
      "loss: 1.002796  [12832/13961]\n",
      "time taken 0.9609944820404053\n",
      "Test Scores: \n",
      " Accuracy: 72.7%, F1:56.1%,  Test loss: 1.012193, Training loss:0.988539 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.70      0.69      0.70      1214\n",
      "         2.0       0.70      0.78      0.74      1739\n",
      "         3.0       0.76      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 69, LR 9.723154317677037e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.948054  [   32/13961]\n",
      "loss: 0.929285  [ 3232/13961]\n",
      "loss: 1.046674  [ 6432/13961]\n",
      "loss: 1.025088  [ 9632/13961]\n",
      "loss: 0.936236  [12832/13961]\n",
      "time taken 0.9352467060089111\n",
      "Test Scores: \n",
      " Accuracy: 73.2%, F1:56.5%,  Test loss: 1.009453, Training loss:0.989539 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.70      0.70      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.57      5984\n",
      "weighted avg       0.66      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 70, LR 9.784683939408622e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.990254  [   32/13961]\n",
      "loss: 0.823753  [ 3232/13961]\n",
      "loss: 0.872535  [ 6432/13961]\n",
      "loss: 0.986075  [ 9632/13961]\n",
      "loss: 1.013655  [12832/13961]\n",
      "time taken 0.919583797454834\n",
      "Test Scores: \n",
      " Accuracy: 73.1%, F1:56.5%,  Test loss: 1.008384, Training loss:0.987537 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.69      0.71      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 71, LR 9.808811876520488e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.192668  [   32/13961]\n",
      "loss: 1.074148  [ 3232/13961]\n",
      "loss: 0.977743  [ 6432/13961]\n",
      "loss: 0.956168  [ 9632/13961]\n",
      "loss: 0.909001  [12832/13961]\n",
      "time taken 0.948817253112793\n",
      "Test Scores: \n",
      " Accuracy: 73.2%, F1:56.5%,  Test loss: 1.008527, Training loss:0.989401 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.69      0.70      1214\n",
      "         2.0       0.70      0.80      0.74      1739\n",
      "         3.0       0.77      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 72, LR 9.805578860791096e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.035416  [   32/13961]\n",
      "loss: 1.048843  [ 3232/13961]\n",
      "loss: 1.008832  [ 6432/13961]\n",
      "loss: 1.117156  [ 9632/13961]\n",
      "loss: 0.881602  [12832/13961]\n",
      "time taken 0.911794900894165\n",
      "Test Scores: \n",
      " Accuracy: 73.4%, F1:56.7%,  Test loss: 1.008051, Training loss:0.987696 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.70      0.71      1214\n",
      "         2.0       0.69      0.81      0.75      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 73, LR 9.816323684198083e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.992927  [   32/13961]\n",
      "loss: 0.874142  [ 3232/13961]\n",
      "loss: 0.965167  [ 6432/13961]\n",
      "loss: 0.966617  [ 9632/13961]\n",
      "loss: 0.971456  [12832/13961]\n",
      "time taken 0.9795112609863281\n",
      "Test Scores: \n",
      " Accuracy: 73.6%, F1:56.9%,  Test loss: 1.007150, Training loss:0.987513 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.72      0.71      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 74, LR 9.836702743612783e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.994411  [   32/13961]\n",
      "loss: 0.869208  [ 3232/13961]\n",
      "loss: 0.976998  [ 6432/13961]\n",
      "loss: 0.926652  [ 9632/13961]\n",
      "loss: 1.001348  [12832/13961]\n",
      "time taken 0.8966517448425293\n",
      "Test Scores: \n",
      " Accuracy: 73.1%, F1:56.5%,  Test loss: 1.010411, Training loss:0.985010 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.70      0.71      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 75, LR 9.763121752826183e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.956706  [   32/13961]\n",
      "loss: 1.017357  [ 3232/13961]\n",
      "loss: 0.868404  [ 6432/13961]\n",
      "loss: 1.012693  [ 9632/13961]\n",
      "loss: 1.063627  [12832/13961]\n",
      "time taken 0.9115803241729736\n",
      "Test Scores: \n",
      " Accuracy: 73.1%, F1:56.4%,  Test loss: 1.009168, Training loss:0.986486 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.70      0.71      0.70      1214\n",
      "         2.0       0.69      0.79      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.56      5984\n",
      "weighted avg       0.66      0.73      0.69      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 76, LR 9.79110867007878e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.870399  [   32/13961]\n",
      "loss: 1.105358  [ 3232/13961]\n",
      "loss: 0.775238  [ 6432/13961]\n",
      "loss: 0.962938  [ 9632/13961]\n",
      "loss: 0.915349  [12832/13961]\n",
      "time taken 0.9310522079467773\n",
      "Test Scores: \n",
      " Accuracy: 73.4%, F1:56.8%,  Test loss: 1.004360, Training loss:0.985969 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.71      0.71      1214\n",
      "         2.0       0.70      0.80      0.75      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.57      5984\n",
      "weighted avg       0.67      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 77, LR 9.900107070345993e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.980576  [   32/13961]\n",
      "loss: 1.042609  [ 3232/13961]\n",
      "loss: 0.985645  [ 6432/13961]\n",
      "loss: 0.850724  [ 9632/13961]\n",
      "loss: 1.001636  [12832/13961]\n",
      "time taken 0.8849139213562012\n",
      "Test Scores: \n",
      " Accuracy: 73.3%, F1:56.7%,  Test loss: 1.007422, Training loss:0.984861 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.71      0.71      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.77      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.57      5984\n",
      "weighted avg       0.67      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 78, LR 9.830555330879124e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.883268  [   32/13961]\n",
      "loss: 0.851786  [ 3232/13961]\n",
      "loss: 0.945266  [ 6432/13961]\n",
      "loss: 1.015248  [ 9632/13961]\n",
      "loss: 1.083378  [12832/13961]\n",
      "time taken 0.9255266189575195\n",
      "Test Scores: \n",
      " Accuracy: 73.6%, F1:56.9%,  Test loss: 1.005665, Training loss:0.984777 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.70      0.71      1214\n",
      "         2.0       0.70      0.80      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 79, LR 9.870406345121e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.969761  [   32/13961]\n",
      "loss: 1.003614  [ 3232/13961]\n",
      "loss: 0.987974  [ 6432/13961]\n",
      "loss: 1.081292  [ 9632/13961]\n",
      "loss: 1.018035  [12832/13961]\n",
      "time taken 0.8983922004699707\n",
      "Test Scores: \n",
      " Accuracy: 73.4%, F1:56.7%,  Test loss: 1.009213, Training loss:0.982969 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.69      0.71      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.76      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 80, LR 9.790095700386525e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.911238  [   32/13961]\n",
      "loss: 0.941350  [ 3232/13961]\n",
      "loss: 1.038969  [ 6432/13961]\n",
      "loss: 1.026910  [ 9632/13961]\n",
      "loss: 1.017431  [12832/13961]\n",
      "time taken 0.9417741298675537\n",
      "Test Scores: \n",
      " Accuracy: 73.5%, F1:56.9%,  Test loss: 1.005102, Training loss:0.982888 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.70      0.71      1214\n",
      "         2.0       0.70      0.80      0.75      1739\n",
      "         3.0       0.77      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 81, LR 9.883214374635171e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.968372  [   32/13961]\n",
      "loss: 0.995376  [ 3232/13961]\n",
      "loss: 0.988250  [ 6432/13961]\n",
      "loss: 0.975094  [ 9632/13961]\n",
      "loss: 0.918997  [12832/13961]\n",
      "time taken 0.941403865814209\n",
      "Test Scores: \n",
      " Accuracy: 73.5%, F1:56.8%,  Test loss: 1.005969, Training loss:0.982532 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.69      0.71      1214\n",
      "         2.0       0.70      0.80      0.75      1739\n",
      "         3.0       0.76      0.87      0.81      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 82, LR 9.863490338485621e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.982336  [   32/13961]\n",
      "loss: 0.926886  [ 3232/13961]\n",
      "loss: 0.979236  [ 6432/13961]\n",
      "loss: 1.064119  [ 9632/13961]\n",
      "loss: 0.909938  [12832/13961]\n",
      "time taken 0.9507901668548584\n",
      "Test Scores: \n",
      " Accuracy: 73.6%, F1:56.9%,  Test loss: 1.004914, Training loss:0.983833 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.70      0.71      1214\n",
      "         2.0       0.70      0.80      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 83, LR 9.887493571017304e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.994443  [   32/13961]\n",
      "loss: 1.101316  [ 3232/13961]\n",
      "loss: 0.964547  [ 6432/13961]\n",
      "loss: 1.068711  [ 9632/13961]\n",
      "loss: 1.023545  [12832/13961]\n",
      "time taken 0.9923114776611328\n",
      "Test Scores: \n",
      " Accuracy: 73.3%, F1:56.7%,  Test loss: 1.004539, Training loss:0.982024 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.70      0.71      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.77      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.54      0.59      0.57      5984\n",
      "weighted avg       0.67      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 84, LR 9.896037891068564e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.002050  [   32/13961]\n",
      "loss: 0.936755  [ 3232/13961]\n",
      "loss: 0.978778  [ 6432/13961]\n",
      "loss: 1.008944  [ 9632/13961]\n",
      "loss: 0.929575  [12832/13961]\n",
      "time taken 0.9166688919067383\n",
      "Test Scores: \n",
      " Accuracy: 73.4%, F1:56.8%,  Test loss: 1.005939, Training loss:0.980961 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.70      0.71      1214\n",
      "         2.0       0.69      0.80      0.74      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 85, LR 9.864187814609683e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.989736  [   32/13961]\n",
      "loss: 0.948739  [ 3232/13961]\n",
      "loss: 0.883808  [ 6432/13961]\n",
      "loss: 0.886279  [ 9632/13961]\n",
      "loss: 0.941117  [12832/13961]\n",
      "time taken 0.9610252380371094\n",
      "Test Scores: \n",
      " Accuracy: 73.8%, F1:57.1%,  Test loss: 1.003034, Training loss:0.980958 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.72      0.72      1214\n",
      "         2.0       0.70      0.80      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 86, LR 9.930393991681488e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.900199  [   32/13961]\n",
      "loss: 0.855250  [ 3232/13961]\n",
      "loss: 0.965159  [ 6432/13961]\n",
      "loss: 0.886265  [ 9632/13961]\n",
      "loss: 1.023189  [12832/13961]\n",
      "time taken 1.0086698532104492\n",
      "Test Scores: \n",
      " Accuracy: 73.4%, F1:56.8%,  Test loss: 1.004440, Training loss:0.979488 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.71      0.72      1214\n",
      "         2.0       0.70      0.80      0.75      1739\n",
      "         3.0       0.76      0.86      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 87, LR 9.898278494302643e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.992085  [   32/13961]\n",
      "loss: 0.991657  [ 3232/13961]\n",
      "loss: 1.070263  [ 6432/13961]\n",
      "loss: 1.022641  [ 9632/13961]\n",
      "loss: 1.086151  [12832/13961]\n",
      "time taken 0.909125566482544\n",
      "Test Scores: \n",
      " Accuracy: 73.7%, F1:56.9%,  Test loss: 1.003720, Training loss:0.980899 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.70      0.71      1214\n",
      "         2.0       0.69      0.81      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 88, LR 9.914710035142871e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.096874  [   32/13961]\n",
      "loss: 0.845512  [ 3232/13961]\n",
      "loss: 0.892523  [ 6432/13961]\n",
      "loss: 0.938158  [ 9632/13961]\n",
      "loss: 0.987383  [12832/13961]\n",
      "time taken 0.9344635009765625\n",
      "Test Scores: \n",
      " Accuracy: 73.7%, F1:57.0%,  Test loss: 1.004991, Training loss:0.979710 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.72      0.72      1214\n",
      "         2.0       0.69      0.81      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 89, LR 9.885727580837238e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.076528  [   32/13961]\n",
      "loss: 0.929326  [ 3232/13961]\n",
      "loss: 1.075488  [ 6432/13961]\n",
      "loss: 1.033408  [ 9632/13961]\n",
      "loss: 0.969877  [12832/13961]\n",
      "time taken 0.8925802707672119\n",
      "Test Scores: \n",
      " Accuracy: 73.7%, F1:56.9%,  Test loss: 1.003749, Training loss:0.980334 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.70      0.71      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 90, LR 9.914048736554629e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.946950  [   32/13961]\n",
      "loss: 0.963495  [ 3232/13961]\n",
      "loss: 0.964027  [ 6432/13961]\n",
      "loss: 0.965532  [ 9632/13961]\n",
      "loss: 1.019351  [12832/13961]\n",
      "time taken 0.9392850399017334\n",
      "Test Scores: \n",
      " Accuracy: 73.5%, F1:56.8%,  Test loss: 1.003780, Training loss:0.979386 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.70      0.71      1214\n",
      "         2.0       0.69      0.83      0.75      1739\n",
      "         3.0       0.78      0.85      0.81      2479\n",
      "\n",
      "    accuracy                           0.73      5984\n",
      "   macro avg       0.55      0.59      0.57      5984\n",
      "weighted avg       0.67      0.73      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 91, LR 9.913342787397051e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.965696  [   32/13961]\n",
      "loss: 0.898866  [ 3232/13961]\n",
      "loss: 1.052534  [ 6432/13961]\n",
      "loss: 0.960230  [ 9632/13961]\n",
      "loss: 1.041735  [12832/13961]\n",
      "time taken 0.9553053379058838\n",
      "Test Scores: \n",
      " Accuracy: 73.9%, F1:57.2%,  Test loss: 1.001136, Training loss:0.977429 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.71      0.72      0.72      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 92, LR 9.973878486934619e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.936172  [   32/13961]\n",
      "loss: 1.004857  [ 3232/13961]\n",
      "loss: 0.941789  [ 6432/13961]\n",
      "loss: 1.031554  [ 9632/13961]\n",
      "loss: 0.978674  [12832/13961]\n",
      "time taken 0.9095697402954102\n",
      "Test Scores: \n",
      " Accuracy: 73.9%, F1:57.2%,  Test loss: 1.001753, Training loss:0.978049 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.72      0.71      0.72      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 93, LR 9.95971912066315e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.017206  [   32/13961]\n",
      "loss: 1.006613  [ 3232/13961]\n",
      "loss: 1.070181  [ 6432/13961]\n",
      "loss: 0.971842  [ 9632/13961]\n",
      "loss: 1.052320  [12832/13961]\n",
      "time taken 0.9578118324279785\n",
      "Test Scores: \n",
      " Accuracy: 74.0%, F1:57.2%,  Test loss: 1.001451, Training loss:0.975816 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.71      0.72      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 94, LR 9.966635567159002e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.005377  [   32/13961]\n",
      "loss: 0.942017  [ 3232/13961]\n",
      "loss: 1.005819  [ 6432/13961]\n",
      "loss: 0.941000  [ 9632/13961]\n",
      "loss: 0.999474  [12832/13961]\n",
      "time taken 0.9233176708221436\n",
      "Test Scores: \n",
      " Accuracy: 73.9%, F1:57.2%,  Test loss: 1.001592, Training loss:0.976865 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.71      0.72      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 95, LR 9.96340697676781e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.913161  [   32/13961]\n",
      "loss: 1.011846  [ 3232/13961]\n",
      "loss: 0.997571  [ 6432/13961]\n",
      "loss: 1.042099  [ 9632/13961]\n",
      "loss: 1.107848  [12832/13961]\n",
      "time taken 0.9334018230438232\n",
      "Test Scores: \n",
      " Accuracy: 74.0%, F1:57.3%,  Test loss: 0.999149, Training loss:0.977241 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.70      0.72      1214\n",
      "         2.0       0.69      0.81      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 96, LR 0.00010019612652209634\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.888770  [   32/13961]\n",
      "loss: 0.903910  [ 3232/13961]\n",
      "loss: 0.982526  [ 6432/13961]\n",
      "loss: 1.073021  [ 9632/13961]\n",
      "loss: 0.998776  [12832/13961]\n",
      "time taken 0.9583008289337158\n",
      "Test Scores: \n",
      " Accuracy: 74.1%, F1:57.4%,  Test loss: 0.999676, Training loss:0.974900 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.72      0.73      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 97, LR 0.0001000746131598841\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.903143  [   32/13961]\n",
      "loss: 1.154807  [ 3232/13961]\n",
      "loss: 0.933805  [ 6432/13961]\n",
      "loss: 0.860202  [ 9632/13961]\n",
      "loss: 0.968760  [12832/13961]\n",
      "time taken 0.9051485061645508\n",
      "Test Scores: \n",
      " Accuracy: 73.7%, F1:57.0%,  Test loss: 1.001182, Training loss:0.975998 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.70      0.72      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 98, LR 9.972827768196526e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.068960  [   32/13961]\n",
      "loss: 1.023054  [ 3232/13961]\n",
      "loss: 1.019556  [ 6432/13961]\n",
      "loss: 1.006307  [ 9632/13961]\n",
      "loss: 0.984557  [12832/13961]\n",
      "time taken 0.9728169441223145\n",
      "Test Scores: \n",
      " Accuracy: 74.2%, F1:57.6%,  Test loss: 0.999858, Training loss:0.974966 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.72      0.73      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 99, LR 0.00010003260894744196\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.895062  [   32/13961]\n",
      "loss: 0.986785  [ 3232/13961]\n",
      "loss: 0.997023  [ 6432/13961]\n",
      "loss: 0.876181  [ 9632/13961]\n",
      "loss: 0.964288  [12832/13961]\n",
      "time taken 0.9185237884521484\n",
      "Test Scores: \n",
      " Accuracy: 74.2%, F1:57.4%,  Test loss: 0.998935, Training loss:0.976062 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.72      0.73      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 100, LR 0.00010024551906571981\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.848354  [   32/13961]\n",
      "loss: 0.957496  [ 3232/13961]\n",
      "loss: 1.057496  [ 6432/13961]\n",
      "loss: 0.982086  [ 9632/13961]\n",
      "loss: 1.056554  [12832/13961]\n",
      "time taken 0.964838981628418\n",
      "Test Scores: \n",
      " Accuracy: 74.3%, F1:57.5%,  Test loss: 0.998507, Training loss:0.976247 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.72      0.73      1214\n",
      "         2.0       0.70      0.82      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 101, LR 0.00010034444341788981\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.121164  [   32/13961]\n",
      "loss: 1.023265  [ 3232/13961]\n",
      "loss: 0.994523  [ 6432/13961]\n",
      "loss: 0.936390  [ 9632/13961]\n",
      "loss: 1.011668  [12832/13961]\n",
      "time taken 0.9083478450775146\n",
      "Test Scores: \n",
      " Accuracy: 73.9%, F1:57.2%,  Test loss: 1.000661, Training loss:0.974264 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.72      0.73      1214\n",
      "         2.0       0.69      0.81      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 102, LR 9.984790890785475e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.900549  [   32/13961]\n",
      "loss: 1.101720  [ 3232/13961]\n",
      "loss: 1.043931  [ 6432/13961]\n",
      "loss: 0.947340  [ 9632/13961]\n",
      "loss: 0.986423  [12832/13961]\n",
      "time taken 0.9379215240478516\n",
      "Test Scores: \n",
      " Accuracy: 74.3%, F1:57.5%,  Test loss: 0.999468, Training loss:0.974501 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.73      0.73      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 103, LR 0.0001001225507939857\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.972018  [   32/13961]\n",
      "loss: 0.891518  [ 3232/13961]\n",
      "loss: 1.016921  [ 6432/13961]\n",
      "loss: 0.944198  [ 9632/13961]\n",
      "loss: 1.027868  [12832/13961]\n",
      "time taken 0.9724433422088623\n",
      "Test Scores: \n",
      " Accuracy: 74.5%, F1:57.8%,  Test loss: 0.997915, Training loss:0.974369 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.73      0.73      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 104, LR 0.00010048116121324584\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.076303  [   32/13961]\n",
      "loss: 1.006861  [ 3232/13961]\n",
      "loss: 1.051329  [ 6432/13961]\n",
      "loss: 0.984655  [ 9632/13961]\n",
      "loss: 1.053513  [12832/13961]\n",
      "time taken 0.9500758647918701\n",
      "Test Scores: \n",
      " Accuracy: 74.2%, F1:57.5%,  Test loss: 0.998564, Training loss:0.973818 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.72      0.73      1214\n",
      "         2.0       0.69      0.83      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 105, LR 0.00010033117827021975\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.017426  [   32/13961]\n",
      "loss: 0.962880  [ 3232/13961]\n",
      "loss: 0.960130  [ 6432/13961]\n",
      "loss: 0.880196  [ 9632/13961]\n",
      "loss: 1.054667  [12832/13961]\n",
      "time taken 0.9662575721740723\n",
      "Test Scores: \n",
      " Accuracy: 74.0%, F1:57.2%,  Test loss: 0.998567, Training loss:0.972354 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.71      0.72      1214\n",
      "         2.0       0.70      0.82      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 106, LR 0.00010033059595854264\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.023387  [   32/13961]\n",
      "loss: 1.041728  [ 3232/13961]\n",
      "loss: 0.928955  [ 6432/13961]\n",
      "loss: 0.967280  [ 9632/13961]\n",
      "loss: 0.963863  [12832/13961]\n",
      "time taken 0.9463932514190674\n",
      "Test Scores: \n",
      " Accuracy: 74.0%, F1:57.3%,  Test loss: 1.000122, Training loss:0.972542 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.71      0.72      1214\n",
      "         2.0       0.69      0.83      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 107, LR 9.997198823056877e-05\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.145172  [   32/13961]\n",
      "loss: 0.847415  [ 3232/13961]\n",
      "loss: 0.933629  [ 6432/13961]\n",
      "loss: 0.972841  [ 9632/13961]\n",
      "loss: 1.027350  [12832/13961]\n",
      "time taken 0.9341323375701904\n",
      "Test Scores: \n",
      " Accuracy: 74.6%, F1:57.9%,  Test loss: 0.996669, Training loss:0.972241 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.72      0.74      1214\n",
      "         2.0       0.69      0.83      0.76      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 108, LR 0.0001007699530581431\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.089487  [   32/13961]\n",
      "loss: 0.875867  [ 3232/13961]\n",
      "loss: 0.905327  [ 6432/13961]\n",
      "loss: 0.875021  [ 9632/13961]\n",
      "loss: 0.962763  [12832/13961]\n",
      "time taken 0.9803519248962402\n",
      "Test Scores: \n",
      " Accuracy: 74.2%, F1:57.5%,  Test loss: 0.997650, Training loss:0.971687 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.71      0.73      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 109, LR 0.00010054253379552502\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.883107  [   32/13961]\n",
      "loss: 1.137675  [ 3232/13961]\n",
      "loss: 1.034268  [ 6432/13961]\n",
      "loss: 0.881358  [ 9632/13961]\n",
      "loss: 1.101661  [12832/13961]\n",
      "time taken 0.9183180332183838\n",
      "Test Scores: \n",
      " Accuracy: 74.5%, F1:57.7%,  Test loss: 0.996006, Training loss:0.972083 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.72      0.73      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.78      0.88      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 110, LR 0.00010092378987755031\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.878555  [   32/13961]\n",
      "loss: 0.918908  [ 3232/13961]\n",
      "loss: 1.034988  [ 6432/13961]\n",
      "loss: 1.014954  [ 9632/13961]\n",
      "loss: 1.079466  [12832/13961]\n",
      "time taken 0.9225342273712158\n",
      "Test Scores: \n",
      " Accuracy: 74.6%, F1:57.8%,  Test loss: 0.995629, Training loss:0.971273 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.71      0.73      1214\n",
      "         2.0       0.70      0.82      0.75      1739\n",
      "         3.0       0.78      0.88      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 111, LR 0.00010101146650374808\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.923579  [   32/13961]\n",
      "loss: 0.899964  [ 3232/13961]\n",
      "loss: 0.960565  [ 6432/13961]\n",
      "loss: 0.967339  [ 9632/13961]\n",
      "loss: 0.892740  [12832/13961]\n",
      "time taken 0.9813010692596436\n",
      "Test Scores: \n",
      " Accuracy: 74.4%, F1:57.6%,  Test loss: 0.996777, Training loss:0.970630 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.72      0.73      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.68      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 112, LR 0.0001007447697296985\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.998786  [   32/13961]\n",
      "loss: 1.033717  [ 3232/13961]\n",
      "loss: 1.021492  [ 6432/13961]\n",
      "loss: 0.969412  [ 9632/13961]\n",
      "loss: 0.884066  [12832/13961]\n",
      "time taken 0.9291660785675049\n",
      "Test Scores: \n",
      " Accuracy: 74.3%, F1:57.5%,  Test loss: 0.998037, Training loss:0.973404 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.72      0.73      1214\n",
      "         2.0       0.70      0.82      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 113, LR 0.00010045306671219368\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.852427  [   32/13961]\n",
      "loss: 0.889022  [ 3232/13961]\n",
      "loss: 1.011025  [ 6432/13961]\n",
      "loss: 0.904687  [ 9632/13961]\n",
      "loss: 0.912364  [12832/13961]\n",
      "time taken 0.9525289535522461\n",
      "Test Scores: \n",
      " Accuracy: 74.5%, F1:57.8%,  Test loss: 0.996139, Training loss:0.972534 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.72      0.74      1214\n",
      "         2.0       0.70      0.82      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 114, LR 0.00010089298774273996\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.842693  [   32/13961]\n",
      "loss: 0.980382  [ 3232/13961]\n",
      "loss: 0.909647  [ 6432/13961]\n",
      "loss: 0.901553  [ 9632/13961]\n",
      "loss: 0.832093  [12832/13961]\n",
      "time taken 0.9319398403167725\n",
      "Test Scores: \n",
      " Accuracy: 74.7%, F1:57.9%,  Test loss: 0.993111, Training loss:0.969920 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.73      0.74      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 115, LR 0.00010159899480155646\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.996032  [   32/13961]\n",
      "loss: 0.983619  [ 3232/13961]\n",
      "loss: 0.931213  [ 6432/13961]\n",
      "loss: 0.931617  [ 9632/13961]\n",
      "loss: 0.972255  [12832/13961]\n",
      "time taken 0.9265546798706055\n",
      "Test Scores: \n",
      " Accuracy: 74.3%, F1:57.5%,  Test loss: 0.996602, Training loss:0.968953 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.71      0.73      1214\n",
      "         2.0       0.71      0.81      0.75      1739\n",
      "         3.0       0.77      0.88      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 116, LR 0.00010078552686096858\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.932269  [   32/13961]\n",
      "loss: 1.088255  [ 3232/13961]\n",
      "loss: 0.903736  [ 6432/13961]\n",
      "loss: 0.930300  [ 9632/13961]\n",
      "loss: 0.985653  [12832/13961]\n",
      "time taken 0.9295022487640381\n",
      "Test Scores: \n",
      " Accuracy: 74.5%, F1:57.7%,  Test loss: 0.996490, Training loss:0.970830 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.73      0.73      1214\n",
      "         2.0       0.69      0.81      0.75      1739\n",
      "         3.0       0.78      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 117, LR 0.00010081153809550765\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.980563  [   32/13961]\n",
      "loss: 1.084432  [ 3232/13961]\n",
      "loss: 1.067740  [ 6432/13961]\n",
      "loss: 0.934872  [ 9632/13961]\n",
      "loss: 0.929060  [12832/13961]\n",
      "time taken 0.9178371429443359\n",
      "Test Scores: \n",
      " Accuracy: 74.5%, F1:57.8%,  Test loss: 0.995319, Training loss:0.969433 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.73      0.73      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.79      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 118, LR 0.00010108361564356236\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.000346  [   32/13961]\n",
      "loss: 1.146403  [ 3232/13961]\n",
      "loss: 0.952731  [ 6432/13961]\n",
      "loss: 1.006537  [ 9632/13961]\n",
      "loss: 0.858825  [12832/13961]\n",
      "time taken 0.9358904361724854\n",
      "Test Scores: \n",
      " Accuracy: 74.6%, F1:57.9%,  Test loss: 0.995514, Training loss:0.969702 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.72      0.74      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.88      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 119, LR 0.00010103818312330189\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.901119  [   32/13961]\n",
      "loss: 1.051840  [ 3232/13961]\n",
      "loss: 0.938709  [ 6432/13961]\n",
      "loss: 0.962506  [ 9632/13961]\n",
      "loss: 0.956513  [12832/13961]\n",
      "time taken 0.9086165428161621\n",
      "Test Scores: \n",
      " Accuracy: 73.9%, F1:57.3%,  Test loss: 0.998929, Training loss:0.969519 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.72      0.73      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 120, LR 0.00010024699487973505\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.062667  [   32/13961]\n",
      "loss: 0.983588  [ 3232/13961]\n",
      "loss: 0.998935  [ 6432/13961]\n",
      "loss: 0.938507  [ 9632/13961]\n",
      "loss: 1.151689  [12832/13961]\n",
      "time taken 0.9096157550811768\n",
      "Test Scores: \n",
      " Accuracy: 74.3%, F1:57.6%,  Test loss: 0.996657, Training loss:0.968803 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.73      0.73      1214\n",
      "         2.0       0.69      0.81      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 121, LR 0.00010077281934175199\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.960237  [   32/13961]\n",
      "loss: 0.974063  [ 3232/13961]\n",
      "loss: 1.044854  [ 6432/13961]\n",
      "loss: 0.908830  [ 9632/13961]\n",
      "loss: 0.992704  [12832/13961]\n",
      "time taken 0.8803350925445557\n",
      "Test Scores: \n",
      " Accuracy: 74.5%, F1:57.7%,  Test loss: 0.994688, Training loss:0.969729 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.72      0.73      1214\n",
      "         2.0       0.70      0.82      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 122, LR 0.00010123071896857939\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.968358  [   32/13961]\n",
      "loss: 1.104446  [ 3232/13961]\n",
      "loss: 0.979061  [ 6432/13961]\n",
      "loss: 0.926548  [ 9632/13961]\n",
      "loss: 1.010786  [12832/13961]\n",
      "time taken 0.863520622253418\n",
      "Test Scores: \n",
      " Accuracy: 74.8%, F1:58.0%,  Test loss: 0.994310, Training loss:0.967610 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.72      0.74      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.88      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 123, LR 0.00010131883519983953\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.976798  [   32/13961]\n",
      "loss: 1.162246  [ 3232/13961]\n",
      "loss: 0.991036  [ 6432/13961]\n",
      "loss: 0.994236  [ 9632/13961]\n",
      "loss: 1.053777  [12832/13961]\n",
      "time taken 0.9772088527679443\n",
      "Test Scores: \n",
      " Accuracy: 74.7%, F1:57.9%,  Test loss: 0.993146, Training loss:0.969300 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.73      0.73      0.73      1214\n",
      "         2.0       0.71      0.81      0.76      1739\n",
      "         3.0       0.78      0.88      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 124, LR 0.00010159063199392007\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.058617  [   32/13961]\n",
      "loss: 0.930872  [ 3232/13961]\n",
      "loss: 1.026982  [ 6432/13961]\n",
      "loss: 0.974446  [ 9632/13961]\n",
      "loss: 0.967732  [12832/13961]\n",
      "time taken 0.94815993309021\n",
      "Test Scores: \n",
      " Accuracy: 74.6%, F1:57.9%,  Test loss: 0.993559, Training loss:0.967685 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.73      0.74      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 125, LR 0.00010149417660852196\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.881198  [   32/13961]\n",
      "loss: 0.964978  [ 3232/13961]\n",
      "loss: 1.092380  [ 6432/13961]\n",
      "loss: 1.002908  [ 9632/13961]\n",
      "loss: 0.953577  [12832/13961]\n",
      "time taken 0.9887411594390869\n",
      "Test Scores: \n",
      " Accuracy: 75.0%, F1:58.1%,  Test loss: 0.993257, Training loss:0.967375 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.73      0.74      1214\n",
      "         2.0       0.69      0.83      0.76      1739\n",
      "         3.0       0.79      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 126, LR 0.00010156471089673927\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.028486  [   32/13961]\n",
      "loss: 0.818213  [ 3232/13961]\n",
      "loss: 1.029530  [ 6432/13961]\n",
      "loss: 0.912688  [ 9632/13961]\n",
      "loss: 1.036737  [12832/13961]\n",
      "time taken 0.9688551425933838\n",
      "Test Scores: \n",
      " Accuracy: 74.0%, F1:57.3%,  Test loss: 0.998657, Training loss:0.967681 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.71      0.73      1214\n",
      "         2.0       0.69      0.81      0.74      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.57      5984\n",
      "weighted avg       0.67      0.74      0.70      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 127, LR 0.00010030965192151985\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.028793  [   32/13961]\n",
      "loss: 0.996128  [ 3232/13961]\n",
      "loss: 1.059888  [ 6432/13961]\n",
      "loss: 0.999808  [ 9632/13961]\n",
      "loss: 1.043854  [12832/13961]\n",
      "time taken 0.9240231513977051\n",
      "Test Scores: \n",
      " Accuracy: 74.2%, F1:57.5%,  Test loss: 0.997422, Training loss:0.966787 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.73      0.74      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.78      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.67      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 128, LR 0.00010059535220988536\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.985938  [   32/13961]\n",
      "loss: 0.937011  [ 3232/13961]\n",
      "loss: 0.985124  [ 6432/13961]\n",
      "loss: 0.985745  [ 9632/13961]\n",
      "loss: 0.934333  [12832/13961]\n",
      "time taken 0.977879524230957\n",
      "Test Scores: \n",
      " Accuracy: 74.4%, F1:57.7%,  Test loss: 0.995579, Training loss:0.965769 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.73      0.73      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.79      0.86      0.82      2479\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.55      0.60      0.58      5984\n",
      "weighted avg       0.68      0.74      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 129, LR 0.00010102324446731478\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.820424  [   32/13961]\n",
      "loss: 1.034004  [ 3232/13961]\n",
      "loss: 0.992064  [ 6432/13961]\n",
      "loss: 1.055140  [ 9632/13961]\n",
      "loss: 1.013257  [12832/13961]\n",
      "time taken 0.9546136856079102\n",
      "Test Scores: \n",
      " Accuracy: 74.8%, F1:57.9%,  Test loss: 0.993109, Training loss:0.966152 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.71      0.73      1214\n",
      "         2.0       0.71      0.82      0.76      1739\n",
      "         3.0       0.78      0.89      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 130, LR 0.0001015994164758324\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.952655  [   32/13961]\n",
      "loss: 0.932612  [ 3232/13961]\n",
      "loss: 1.001211  [ 6432/13961]\n",
      "loss: 0.992874  [ 9632/13961]\n",
      "loss: 0.817236  [12832/13961]\n",
      "time taken 0.9443445205688477\n",
      "Test Scores: \n",
      " Accuracy: 74.7%, F1:57.9%,  Test loss: 0.992667, Training loss:0.967230 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.72      0.74      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.78      0.88      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 131, LR 0.00010170289020048933\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.993825  [   32/13961]\n",
      "loss: 0.951688  [ 3232/13961]\n",
      "loss: 0.998998  [ 6432/13961]\n",
      "loss: 0.861710  [ 9632/13961]\n",
      "loss: 0.897107  [12832/13961]\n",
      "time taken 0.8946576118469238\n",
      "Test Scores: \n",
      " Accuracy: 74.8%, F1:58.0%,  Test loss: 0.992377, Training loss:0.966802 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.72      0.74      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.77      0.88      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 132, LR 0.00010177082566702733\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.003107  [   32/13961]\n",
      "loss: 0.984849  [ 3232/13961]\n",
      "loss: 0.989397  [ 6432/13961]\n",
      "loss: 0.945775  [ 9632/13961]\n",
      "loss: 0.980287  [12832/13961]\n",
      "time taken 0.9283788204193115\n",
      "Test Scores: \n",
      " Accuracy: 74.7%, F1:57.9%,  Test loss: 0.993550, Training loss:0.965851 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.72      0.74      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 133, LR 0.00010149623268971846\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.911099  [   32/13961]\n",
      "loss: 0.907125  [ 3232/13961]\n",
      "loss: 0.966984  [ 6432/13961]\n",
      "loss: 0.992888  [ 9632/13961]\n",
      "loss: 0.941099  [12832/13961]\n",
      "time taken 0.9646105766296387\n",
      "Test Scores: \n",
      " Accuracy: 74.5%, F1:57.8%,  Test loss: 0.994197, Training loss:0.966331 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.73      0.74      1214\n",
      "         2.0       0.70      0.81      0.75      1739\n",
      "         3.0       0.77      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 134, LR 0.00010134525020542646\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.880006  [   32/13961]\n",
      "loss: 0.891757  [ 3232/13961]\n",
      "loss: 1.061207  [ 6432/13961]\n",
      "loss: 0.996919  [ 9632/13961]\n",
      "loss: 1.015711  [12832/13961]\n",
      "time taken 1.0282506942749023\n",
      "Test Scores: \n",
      " Accuracy: 74.9%, F1:58.1%,  Test loss: 0.992524, Training loss:0.964259 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.74      0.74      0.74      1214\n",
      "         2.0       0.71      0.82      0.76      1739\n",
      "         3.0       0.78      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 135, LR 0.00010173629352672283\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.889372  [   32/13961]\n",
      "loss: 0.901300  [ 3232/13961]\n",
      "loss: 1.010837  [ 6432/13961]\n",
      "loss: 1.008416  [ 9632/13961]\n",
      "loss: 1.152829  [12832/13961]\n",
      "time taken 1.0089006423950195\n",
      "Test Scores: \n",
      " Accuracy: 74.9%, F1:58.0%,  Test loss: 0.991530, Training loss:0.965337 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.77      0.71      0.74      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.88      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 136, LR 0.00010196943004274104\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.115711  [   32/13961]\n",
      "loss: 0.932624  [ 3232/13961]\n",
      "loss: 0.917535  [ 6432/13961]\n",
      "loss: 0.949754  [ 9632/13961]\n",
      "loss: 1.055215  [12832/13961]\n",
      "time taken 0.9712824821472168\n",
      "Test Scores: \n",
      " Accuracy: 74.6%, F1:57.8%,  Test loss: 0.993976, Training loss:0.963966 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.72      0.74      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 137, LR 0.00010139680748399966\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.847342  [   32/13961]\n",
      "loss: 1.014408  [ 3232/13961]\n",
      "loss: 1.045697  [ 6432/13961]\n",
      "loss: 1.017380  [ 9632/13961]\n",
      "loss: 0.841603  [12832/13961]\n",
      "time taken 0.9339566230773926\n",
      "Test Scores: \n",
      " Accuracy: 74.9%, F1:58.1%,  Test loss: 0.991181, Training loss:0.964515 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.73      0.74      1214\n",
      "         2.0       0.70      0.83      0.76      1739\n",
      "         3.0       0.78      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 138, LR 0.00010205143733308568\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.965641  [   32/13961]\n",
      "loss: 0.982585  [ 3232/13961]\n",
      "loss: 0.894752  [ 6432/13961]\n",
      "loss: 0.985930  [ 9632/13961]\n",
      "loss: 1.098315  [12832/13961]\n",
      "time taken 0.955660343170166\n",
      "Test Scores: \n",
      " Accuracy: 75.0%, F1:58.2%,  Test loss: 0.991341, Training loss:0.964634 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.74      0.74      1214\n",
      "         2.0       0.70      0.83      0.76      1739\n",
      "         3.0       0.79      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 139, LR 0.00010201371027762277\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.028056  [   32/13961]\n",
      "loss: 0.900852  [ 3232/13961]\n",
      "loss: 1.049864  [ 6432/13961]\n",
      "loss: 0.974749  [ 9632/13961]\n",
      "loss: 1.032543  [12832/13961]\n",
      "time taken 0.9387977123260498\n",
      "Test Scores: \n",
      " Accuracy: 74.9%, F1:58.0%,  Test loss: 0.991201, Training loss:0.964613 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.72      0.74      1214\n",
      "         2.0       0.70      0.81      0.76      1739\n",
      "         3.0       0.78      0.88      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 140, LR 0.00010204672632409388\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.053805  [   32/13961]\n",
      "loss: 1.061464  [ 3232/13961]\n",
      "loss: 0.919733  [ 6432/13961]\n",
      "loss: 0.958494  [ 9632/13961]\n",
      "loss: 0.999447  [12832/13961]\n",
      "time taken 0.9025318622589111\n",
      "Test Scores: \n",
      " Accuracy: 74.8%, F1:58.1%,  Test loss: 0.992007, Training loss:0.963718 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.73      0.74      1214\n",
      "         2.0       0.69      0.82      0.75      1739\n",
      "         3.0       0.78      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 141, LR 0.00010185750408830548\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.958884  [   32/13961]\n",
      "loss: 1.027611  [ 3232/13961]\n",
      "loss: 1.073806  [ 6432/13961]\n",
      "loss: 0.919114  [ 9632/13961]\n",
      "loss: 0.967741  [12832/13961]\n",
      "time taken 0.9459657669067383\n",
      "Test Scores: \n",
      " Accuracy: 75.1%, F1:58.2%,  Test loss: 0.990447, Training loss:0.964635 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.72      0.74      1214\n",
      "         2.0       0.70      0.83      0.76      1739\n",
      "         3.0       0.79      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 142, LR 0.0001022239673017741\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.087838  [   32/13961]\n",
      "loss: 1.019756  [ 3232/13961]\n",
      "loss: 1.038985  [ 6432/13961]\n",
      "loss: 0.975582  [ 9632/13961]\n",
      "loss: 1.016644  [12832/13961]\n",
      "time taken 0.9351353645324707\n",
      "Test Scores: \n",
      " Accuracy: 75.0%, F1:58.2%,  Test loss: 0.991013, Training loss:0.964601 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.77      0.73      0.75      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.88      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 143, LR 0.00010209086479446273\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.059304  [   32/13961]\n",
      "loss: 0.971685  [ 3232/13961]\n",
      "loss: 0.927397  [ 6432/13961]\n",
      "loss: 0.996206  [ 9632/13961]\n",
      "loss: 0.837424  [12832/13961]\n",
      "time taken 0.9429998397827148\n",
      "Test Scores: \n",
      " Accuracy: 74.8%, F1:58.0%,  Test loss: 0.992657, Training loss:0.964835 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.73      0.74      1214\n",
      "         2.0       0.71      0.81      0.76      1739\n",
      "         3.0       0.78      0.88      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 144, LR 0.00010170514809331622\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.969268  [   32/13961]\n",
      "loss: 0.875027  [ 3232/13961]\n",
      "loss: 0.960869  [ 6432/13961]\n",
      "loss: 1.068735  [ 9632/13961]\n",
      "loss: 0.896265  [12832/13961]\n",
      "time taken 0.9255995750427246\n",
      "Test Scores: \n",
      " Accuracy: 75.0%, F1:58.2%,  Test loss: 0.991530, Training loss:0.963583 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.73      0.74      1214\n",
      "         2.0       0.71      0.81      0.76      1739\n",
      "         3.0       0.78      0.89      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 145, LR 0.00010196954731449598\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.937605  [   32/13961]\n",
      "loss: 0.931961  [ 3232/13961]\n",
      "loss: 0.915923  [ 6432/13961]\n",
      "loss: 0.854457  [ 9632/13961]\n",
      "loss: 0.823829  [12832/13961]\n",
      "time taken 0.9199035167694092\n",
      "Test Scores: \n",
      " Accuracy: 75.0%, F1:58.2%,  Test loss: 0.990514, Training loss:0.964122 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.73      0.74      1214\n",
      "         2.0       0.70      0.83      0.76      1739\n",
      "         3.0       0.78      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 146, LR 0.00010220825666557738\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.013485  [   32/13961]\n",
      "loss: 1.090746  [ 3232/13961]\n",
      "loss: 1.034037  [ 6432/13961]\n",
      "loss: 0.913551  [ 9632/13961]\n",
      "loss: 1.009317  [12832/13961]\n",
      "time taken 0.9651787281036377\n",
      "Test Scores: \n",
      " Accuracy: 74.8%, F1:58.0%,  Test loss: 0.991127, Training loss:0.963152 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.72      0.74      1214\n",
      "         2.0       0.69      0.83      0.75      1739\n",
      "         3.0       0.78      0.87      0.82      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 147, LR 0.00010206410750602108\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 0.994594  [   32/13961]\n",
      "loss: 1.100576  [ 3232/13961]\n",
      "loss: 0.823369  [ 6432/13961]\n",
      "loss: 1.003107  [ 9632/13961]\n",
      "loss: 0.930967  [12832/13961]\n",
      "time taken 0.9304170608520508\n",
      "Test Scores: \n",
      " Accuracy: 75.1%, F1:58.3%,  Test loss: 0.989665, Training loss:0.962284 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.75      0.74      0.74      1214\n",
      "         2.0       0.70      0.83      0.76      1739\n",
      "         3.0       0.79      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Params are saved..\n",
      "Epoch 148, LR 0.00010240831400962486\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.123435  [   32/13961]\n",
      "loss: 1.052779  [ 3232/13961]\n",
      "loss: 0.900788  [ 6432/13961]\n",
      "loss: 0.896962  [ 9632/13961]\n",
      "loss: 1.026887  [12832/13961]\n",
      "time taken 0.9634180068969727\n",
      "Test Scores: \n",
      " Accuracy: 75.1%, F1:58.2%,  Test loss: 0.990043, Training loss:0.961662 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.72      0.74      1214\n",
      "         2.0       0.70      0.82      0.76      1739\n",
      "         3.0       0.78      0.88      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 149, LR 0.00010231919927726039\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.023430  [   32/13961]\n",
      "loss: 0.886896  [ 3232/13961]\n",
      "loss: 0.889085  [ 6432/13961]\n",
      "loss: 0.961776  [ 9632/13961]\n",
      "loss: 0.994686  [12832/13961]\n",
      "time taken 0.9496979713439941\n",
      "Test Scores: \n",
      " Accuracy: 74.9%, F1:58.2%,  Test loss: 0.991887, Training loss:0.961228 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.73      0.75      1214\n",
      "         2.0       0.70      0.82      0.75      1739\n",
      "         3.0       0.78      0.87      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.61      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "Epoch 150, LR 0.00010188564052584577\n",
      "-------------------------------\n",
      "cuda:0\n",
      "loss: 1.031142  [   32/13961]\n",
      "loss: 0.980646  [ 3232/13961]\n",
      "loss: 0.994152  [ 6432/13961]\n",
      "loss: 0.903137  [ 9632/13961]\n",
      "loss: 0.998872  [12832/13961]\n",
      "time taken 0.9235501289367676\n",
      "Test Scores: \n",
      " Accuracy: 74.7%, F1:58.0%,  Test loss: 0.992084, Training loss:0.961179 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       552\n",
      "         1.0       0.76      0.72      0.74      1214\n",
      "         2.0       0.70      0.82      0.75      1739\n",
      "         3.0       0.78      0.88      0.83      2479\n",
      "\n",
      "    accuracy                           0.75      5984\n",
      "   macro avg       0.56      0.60      0.58      5984\n",
      "weighted avg       0.68      0.75      0.71      5984\n",
      "\n",
      "---------------\n",
      "\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Zhai()\n",
    "\n",
    "mps_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available()  )\n",
    "model.to(mps_device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# define the optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "# define the number of epochs\n",
    "epochs = 150\n",
    "# define the save address for the model\n",
    "save_add = dir_manager.dir_dict['user']\n",
    "# define the name of the model\n",
    "number_of_classes = 4\n",
    "model_name = 'Model10_Zhai_Normalized_' + data_name\n",
    "# train the model\n",
    "fm.train_model(model,train_dataloader,test_dataloader,optimizer,criterion,epochs,save_add,model_name,number_of_classes,mps_device ,scheduler )\n",
    "\n",
    "\n",
    "# optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "#                       momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
